{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch and related libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# einops library for tensor operations\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "# Custom TINTO library imports\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.combination import Combination\n",
    "from TINTOlib.featureWrap import FeatureWrap\n",
    "from TINTOlib.bie import BIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: 12.1\n",
      "cuDNN Version: 90100\n",
      "PyTorch Version: 2.5.1+cu121\n",
      "CUDA is available. PyTorch can use GPU.\n",
      "Current GPU: NVIDIA A100-PCIE-40GB MIG 7g.40gb\n",
      "Is this tensor on GPU? True\n",
      "Is CUDA initialized? True\n",
      "Number of available GPUs: 1\n",
      "Current device index: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get CUDA version\n",
    "cuda_version = torch.version.cuda\n",
    "print(f\"CUDA Version: {cuda_version}\")\n",
    "\n",
    "# Get cuDNN version\n",
    "cudnn_version = torch.backends.cudnn.version()\n",
    "print(f\"cuDNN Version: {cudnn_version}\")\n",
    "\n",
    "# Get PyTorch version\n",
    "pytorch_version = torch.__version__\n",
    "print(f\"PyTorch Version: {pytorch_version}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. PyTorch can use GPU.\")\n",
    "    \n",
    "    # Get the name of the current GPU\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Create a random tensor and move it to GPU to verify\n",
    "    x = torch.rand(5, 3)\n",
    "    print(f\"Is this tensor on GPU? {x.cuda().is_cuda}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use CPU.\")\n",
    "\n",
    "# Additional check: is CUDA initialized?\n",
    "print(f\"Is CUDA initialized? {torch.cuda.is_initialized()}\")\n",
    "\n",
    "# Number of available GPUs\n",
    "print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Current device index\n",
    "print(f\"Current device index: {torch.cuda.current_device()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 64\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to store dataset name\n",
    "dataset_name = 'preprocessed_heloc'\n",
    "results_path = f'logs/Binary/{dataset_name}/MLP_Binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"Datasets/Binary/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9871, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the second-to-last column if MIMO\n",
    "# df = df.drop(df.columns[-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ExternalRiskEstimate</th>\n",
       "      <th>MSinceOldestTradeOpen</th>\n",
       "      <th>MSinceMostRecentTradeOpen</th>\n",
       "      <th>AverageMInFile</th>\n",
       "      <th>NumSatisfactoryTrades</th>\n",
       "      <th>NumTrades60Ever2DerogPubRec</th>\n",
       "      <th>NumTrades90Ever2DerogPubRec</th>\n",
       "      <th>PercentTradesNeverDelq</th>\n",
       "      <th>MSinceMostRecentDelq</th>\n",
       "      <th>MaxDelq2PublicRecLast12M</th>\n",
       "      <th>...</th>\n",
       "      <th>MSinceMostRecentInqexcl7days</th>\n",
       "      <th>NumInqLast6M</th>\n",
       "      <th>NumInqLast6Mexcl7days</th>\n",
       "      <th>NetFractionRevolvingBurden</th>\n",
       "      <th>NetFractionInstallBurden</th>\n",
       "      <th>NumRevolvingTradesWBalance</th>\n",
       "      <th>NumInstallTradesWBalance</th>\n",
       "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
       "      <th>PercentTradesWBalance</th>\n",
       "      <th>RiskPerformance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>-8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>15</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>-7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>-8</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>333</td>\n",
       "      <td>27</td>\n",
       "      <td>132</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>-7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>Bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ExternalRiskEstimate  MSinceOldestTradeOpen  MSinceMostRecentTradeOpen  \\\n",
       "0                    55                    144                          4   \n",
       "1                    61                     58                         15   \n",
       "2                    67                     66                          5   \n",
       "3                    66                    169                          1   \n",
       "4                    81                    333                         27   \n",
       "\n",
       "   AverageMInFile  NumSatisfactoryTrades  NumTrades60Ever2DerogPubRec  \\\n",
       "0              84                     20                            3   \n",
       "1              41                      2                            4   \n",
       "2              24                      9                            0   \n",
       "3              73                     28                            1   \n",
       "4             132                     12                            0   \n",
       "\n",
       "   NumTrades90Ever2DerogPubRec  PercentTradesNeverDelq  MSinceMostRecentDelq  \\\n",
       "0                            0                      83                     2   \n",
       "1                            4                     100                    -7   \n",
       "2                            0                     100                    -7   \n",
       "3                            1                      93                    76   \n",
       "4                            0                     100                    -7   \n",
       "\n",
       "   MaxDelq2PublicRecLast12M  ...  MSinceMostRecentInqexcl7days  NumInqLast6M  \\\n",
       "0                         3  ...                             0             0   \n",
       "1                         0  ...                             0             0   \n",
       "2                         7  ...                             0             4   \n",
       "3                         6  ...                             0             5   \n",
       "4                         7  ...                             0             1   \n",
       "\n",
       "   NumInqLast6Mexcl7days  NetFractionRevolvingBurden  \\\n",
       "0                      0                          33   \n",
       "1                      0                           0   \n",
       "2                      4                          53   \n",
       "3                      4                          72   \n",
       "4                      1                          51   \n",
       "\n",
       "   NetFractionInstallBurden  NumRevolvingTradesWBalance  \\\n",
       "0                        -8                           8   \n",
       "1                        -8                           0   \n",
       "2                        66                           4   \n",
       "3                        83                           6   \n",
       "4                        89                           3   \n",
       "\n",
       "   NumInstallTradesWBalance  NumBank2NatlTradesWHighUtilization  \\\n",
       "0                         1                                   1   \n",
       "1                        -8                                  -8   \n",
       "2                         2                                   1   \n",
       "3                         4                                   3   \n",
       "4                         1                                   0   \n",
       "\n",
       "   PercentTradesWBalance  RiskPerformance  \n",
       "0                     69              Bad  \n",
       "1                      0              Bad  \n",
       "2                     86              Bad  \n",
       "3                     91              Bad  \n",
       "4                     80              Bad  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD AND PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Function to load and preprocess only numerical data\n",
    "def load_and_preprocess_numerical_data(batch_size=32):\n",
    "    # Split data\n",
    "    df_x = df.drop(df.columns[-1], axis=1)  # All features except the target\n",
    "    df_y = df[df.columns[-1]]  # Target column\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size=0.20, random_state=SEED)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=SEED)\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Scale numerical data\n",
    "    X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_val = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "    attributes = len(X_train.columns)\n",
    "\n",
    "    print(\"Attributes: \", attributes)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.as_tensor(X_train.values, dtype=torch.float32)\n",
    "    X_val_tensor = torch.as_tensor(X_val.values, dtype=torch.float32)\n",
    "    X_test_tensor = torch.as_tensor(X_test.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.as_tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "    y_val_tensor = torch.as_tensor(y_val.values, dtype=torch.float32).reshape(-1, 1)\n",
    "    y_test_tensor = torch.as_tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iterations_per_epoch(dataset_size, batch_size):\n",
    "    iterations = dataset_size // batch_size\n",
    "    if dataset_size % batch_size != 0:\n",
    "        iterations += 1\n",
    "    return iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = calculate_iterations_per_epoch(df.shape[0], batch_size)\n",
    "# For the Boston dataset, the number of samples is too small for a range test, so the number of epochs is tripled.\n",
    "#num_epochs = num_epochs*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EXPERIMENT 1: LIGHTBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "# Split features and target\n",
    "df_x = df.iloc[:, :-1]  # All columns except the last one (features)\n",
    "df_y = df.iloc[:, -1]   # The last column (target)\n",
    "\n",
    "# Encode target labels as integers\n",
    "label_encoder = LabelEncoder()\n",
    "df_y = label_encoder.fit_transform(df_y)  # Converts string labels to integers\n",
    "\n",
    "# Create train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df_x, df_y, test_size=0.2, random_state=SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the scaler on training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Prepare data in LightGBM Dataset format\n",
    "train_data = lgb.Dataset(X_train_scaled, label=y_train)\n",
    "val_data = lgb.Dataset(X_val_scaled, label=y_val, reference=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM parameters\n",
    "lgb_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"num_leaves\": 34,\n",
    "    \"lambda_l2\": 1.3e-3,\n",
    "    \"lambda_l1\": 2.6e-5,\n",
    "    \"learning_rate\": 7.1e-2,\n",
    "    \"num_iterations\": 1000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM model...\n",
      "[LightGBM] [Info] Number of positive: 3838, number of negative: 4058\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1465\n",
      "[LightGBM] [Info] Number of data points in the train set: 7896, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.486069 -> initscore=-0.055739\n",
      "[LightGBM] [Info] Start training from score -0.055739\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Training LightGBM model...\")\n",
    "lgb_model = lgb.train(\n",
    "    lgb_params,\n",
    "    train_data,\n",
    "    valid_sets=val_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000, AUC: 1.0000\n",
      "Validation Accuracy: 0.7416, AUC: 0.7974\n",
      "Test Accuracy: 0.7136, AUC: 0.7692\n"
     ]
    }
   ],
   "source": [
    "# Predict on train, validation, and test data\n",
    "y_train_prob = lgb_model.predict(X_train_scaled)\n",
    "y_val_prob = lgb_model.predict(X_val_scaled)\n",
    "y_test_prob = lgb_model.predict(X_test_scaled)\n",
    "\n",
    "# Convert probabilities to binary predictions (threshold = 0.5)\n",
    "y_train_pred = (y_train_prob > 0.5).astype(int)\n",
    "y_val_pred = (y_val_prob > 0.5).astype(int)\n",
    "y_test_pred = (y_test_prob > 0.5).astype(int)\n",
    "\n",
    "# Calculate accuracy for each dataset\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_val = accuracy_score(y_val, y_val_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculate AUC for each dataset\n",
    "auc_train = roc_auc_score(y_train, y_train_prob)\n",
    "auc_val = roc_auc_score(y_val, y_val_prob)\n",
    "auc_test = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "# Print results\n",
    "print(f\"Train Accuracy: {accuracy_train:.4f}, AUC: {auc_train:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy_val:.4f}, AUC: {auc_val:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_test:.4f}, AUC: {auc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL METRICS AND BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(base_path):\n",
    "    best_rmse = float('inf')\n",
    "    best_folder = None\n",
    "\n",
    "    # Walk through all directories and files in the base path\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file == f'metrics.txt':\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Read metrics from the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    metrics = f.read()\n",
    "                \n",
    "                # Parse the metrics into a dictionary\n",
    "                metrics_dict = {}\n",
    "                for line in metrics.splitlines():\n",
    "                    key, value = line.split(': ')\n",
    "                    metrics_dict[key.strip()] = float(value.strip())\n",
    "                \n",
    "                # Check if the current folder has a better validation loss\n",
    "                if metrics_dict['test_rmse'] < best_rmse:\n",
    "                    best_rmse = metrics_dict['test_rmse']\n",
    "                    best_folder = root\n",
    "    \n",
    "    return best_folder, best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_metrics(file_path):\n",
    "    metrics = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            key, value = line.split(': ')\n",
    "            metrics[key.strip()] = float(value.strip())\n",
    "    return metrics\n",
    "\n",
    "def rename_folder(old_folder_path, prefix):\n",
    "    folder_name = os.path.basename(old_folder_path)\n",
    "    new_folder_name = f\"{prefix}_{folder_name}\"\n",
    "    parent_dir = os.path.dirname(old_folder_path)\n",
    "    new_folder_path = os.path.join(parent_dir, new_folder_name)\n",
    "    os.rename(old_folder_path, new_folder_path)\n",
    "    return new_folder_path\n",
    "\n",
    "def process_folders(root_dir):\n",
    "    prefixes = [\"_Model\"]\n",
    "    best_folders = []\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        matching_folders = [f for f in os.listdir(root_dir) if f.startswith(prefix) and os.path.isdir(os.path.join(root_dir, f))]\n",
    "        if matching_folders:\n",
    "            best_folder = None\n",
    "            best_test_rmse = float('inf')\n",
    "            for folder in matching_folders:\n",
    "                metrics_file = os.path.join(root_dir, folder, 'metrics.txt')\n",
    "                if os.path.exists(metrics_file):\n",
    "                    metrics = read_metrics(metrics_file)\n",
    "                    if metrics['test_rmse'] < best_test_rmse:\n",
    "                        best_test_rmse = metrics['test_rmse']\n",
    "                        best_folder = folder\n",
    "            if best_folder:\n",
    "                new_path = rename_folder(os.path.join(root_dir, best_folder), \"TOP\")\n",
    "                best_folders.append(new_path)\n",
    "    \n",
    "    if best_folders:\n",
    "        overall_best_folder = None\n",
    "        overall_best_test_rmse = float('inf')\n",
    "        for folder in best_folders:\n",
    "            metrics_file = os.path.join(folder, 'metrics.txt')\n",
    "            if os.path.exists(metrics_file):\n",
    "                metrics = read_metrics(metrics_file)\n",
    "                if metrics['test_rmse'] < overall_best_test_rmse:\n",
    "                    overall_best_test_rmse = metrics['test_rmse']\n",
    "                    overall_best_folder = folder\n",
    "        if overall_best_folder:\n",
    "            rename_folder(overall_best_folder, \"BEST\")\n",
    "        \n",
    "    return best_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "base_path = f\"logs/Regression/{dataset_name}/MLP/\"\n",
    "best_folders = process_folders(base_path)\n",
    "print(f\"Best model folder: {best_folders}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
