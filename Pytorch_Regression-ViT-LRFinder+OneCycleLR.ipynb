{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/conda/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "# Third-party library imports~\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch and related libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# einops library for tensor operations\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "# Custom TINTO library imports\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.combination import Combination\n",
    "from TINTOlib.featureWrap import FeatureWrap\n",
    "from TINTOlib.bie import BIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: 12.1\n",
      "cuDNN Version: 90100\n",
      "PyTorch Version: 2.5.1+cu121\n",
      "CUDA is available. PyTorch can use GPU.\n",
      "Current GPU: NVIDIA A100-PCIE-40GB MIG 7g.40gb\n",
      "Is this tensor on GPU? True\n",
      "Is CUDA initialized? True\n",
      "Number of available GPUs: 1\n",
      "Current device index: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Get CUDA version\n",
    "cuda_version = torch.version.cuda\n",
    "print(f\"CUDA Version: {cuda_version}\")\n",
    "\n",
    "# Get cuDNN version\n",
    "cudnn_version = torch.backends.cudnn.version()\n",
    "print(f\"cuDNN Version: {cudnn_version}\")\n",
    "\n",
    "# Get PyTorch version\n",
    "pytorch_version = torch.__version__\n",
    "print(f\"PyTorch Version: {pytorch_version}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. PyTorch can use GPU.\")\n",
    "    \n",
    "    # Get the name of the current GPU\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Create a random tensor and move it to GPU to verify\n",
    "    x = torch.rand(5, 3)\n",
    "    print(f\"Is this tensor on GPU? {x.cuda().is_cuda}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch will use CPU.\")\n",
    "\n",
    "# Additional check: is CUDA initialized?\n",
    "print(f\"Is CUDA initialized? {torch.cuda.is_initialized()}\")\n",
    "\n",
    "# Number of available GPUs\n",
    "print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "# Current device index\n",
    "print(f\"Current device index: {torch.cuda.current_device()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 64\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable to store dataset name\n",
    "dataset_name = 'california_housing'\n",
    "results_path = f'logs/Regression/{dataset_name}/ViT_Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"Datasets/Regression/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the second-to-last column if MIMO\n",
    "# df = df.drop(df.columns[-2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD AND PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=32):\n",
    "\n",
    "    # Generate the images if the folder does not exist\n",
    "    if not os.path.exists(images_folder):\n",
    "        #Generate thet images\n",
    "        image_model.generateImages(df, images_folder)\n",
    "    else:\n",
    "        print(\"The images are already generated\")\n",
    "\n",
    "    img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "    print(img_paths)\n",
    "    \n",
    "    imgs = pd.read_csv(img_paths)\n",
    "\n",
    "    # Update image paths\n",
    "    imgs[\"images\"] = images_folder + \"/\" + imgs[\"images\"]\n",
    "\n",
    "    # Combine datasets\n",
    "    combined_dataset = pd.concat([imgs, df], axis=1)\n",
    "\n",
    "    # Split data\n",
    "    df_x = combined_dataset.drop(df.columns[-1], axis=1).drop(\"values\", axis=1)\n",
    "    df_y = combined_dataset[\"values\"]\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size=0.20, random_state=SEED)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=SEED)\n",
    "    # Numerical data\n",
    "    X_train_num = X_train.drop(\"images\", axis=1)\n",
    "    X_val_num = X_val.drop(\"images\", axis=1)\n",
    "    X_test_num = X_test.drop(\"images\", axis=1)\n",
    "\n",
    "    # Image data\n",
    "    X_train_img = np.array([cv2.imread(img) for img in X_train[\"images\"]])\n",
    "    X_val_img = np.array([cv2.imread(img) for img in X_val[\"images\"]])\n",
    "    X_test_img = np.array([cv2.imread(img) for img in X_test[\"images\"]])\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Scale numerical data\n",
    "    X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "    X_val_num = pd.DataFrame(scaler.transform(X_val_num), columns=X_val_num.columns)\n",
    "    X_test_num = pd.DataFrame(scaler.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "    attributes = len(X_train_num.columns)\n",
    "    height, width, channels = X_train_img[0].shape\n",
    "    imgs_shape = (channels, height, width)\n",
    "\n",
    "    print(\"Images shape: \", imgs_shape)\n",
    "    print(\"Attributes: \", attributes)\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_num_tensor = torch.as_tensor(X_train_num.values, dtype=torch.float32)\n",
    "    X_val_num_tensor = torch.as_tensor(X_val_num.values, dtype=torch.float32)\n",
    "    X_test_num_tensor = torch.as_tensor(X_test_num.values, dtype=torch.float32)\n",
    "    X_train_img_tensor = torch.as_tensor(X_train_img, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "    X_val_img_tensor = torch.as_tensor(X_val_img, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "    X_test_img_tensor = torch.as_tensor(X_test_img, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "    y_train_tensor = torch.as_tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "    y_val_tensor = torch.as_tensor(y_val.values, dtype=torch.float32).reshape(-1, 1)\n",
    "    y_test_tensor = torch.as_tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_dataset = TensorDataset(X_train_img_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_img_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_img_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, attributes, imgs_shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL ARCHITECTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head *  heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout),\n",
    "                FeedForward(dim, mlp_dim, dropout = dropout)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_divisors(n):\n",
    "    divisors = []\n",
    "    for i in range(1, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            divisors.append(i)\n",
    "            if i != n // i:  # Check to include both divisors if they are not the same\n",
    "                divisors.append(n // i)\n",
    "    divisors.sort()\n",
    "    return divisors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self, imgs_shape, patch_size):\n",
    "        super(Model1, self).__init__()\n",
    "        \n",
    "        # ViT branch\n",
    "        self.vit = ViT(\n",
    "            image_size = imgs_shape[1],\n",
    "            patch_size = patch_size,\n",
    "            dim = 32,\n",
    "            depth = 2,\n",
    "            heads = 4,\n",
    "            mlp_dim = 64,\n",
    "        )\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, vit_input):\n",
    "        vit_output = self.vit(vit_input)\n",
    "        return self.mlp(vit_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, imgs_shape, patch_size):\n",
    "        super(Model2, self).__init__()\n",
    "        \n",
    "        # ViT branch\n",
    "        self.vit = ViT(\n",
    "            image_size = imgs_shape[1],\n",
    "            patch_size = patch_size,\n",
    "            dim = 128,\n",
    "            depth = 4,\n",
    "            heads = 8,\n",
    "            mlp_dim = 256\n",
    "        )\n",
    "        \n",
    "        # Final MLP\n",
    "        self.final_mlp = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, vit_input):\n",
    "        vit_output = self.vit(vit_input)\n",
    "        return self.final_mlp(vit_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## COMPILE AND FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "def compile_and_fit(model, train_loader, val_loader, test_loader, dataset_name, model_name, batch_size=32, epochs=100, min_lr=1e-3, max_lr=1, device='cuda', weight_decay=1e-2):\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=min_lr, weight_decay=weight_decay)\n",
    "    \n",
    "    total_steps = epochs * len(train_loader)\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=max_lr, div_factor=max_lr/min_lr, total_steps=total_steps, pct_start=0.3, final_div_factor=1)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "    early_stopping_patience = 20\n",
    "    best_model = None\n",
    "    best_epoch = 0\n",
    "    warm_up_epochs = epochs*0.3\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_mse': [], 'val_mse': [], 'train_rmse': [], 'val_rmse': [], 'learning_rate': [], 'epoch_time': []}\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_predictions = []\n",
    "        train_targets = []\n",
    "        for img_data, targets in train_loader:\n",
    "            img_data, targets = img_data.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(img_data)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_predictions.extend(outputs.cpu().detach().numpy())\n",
    "            train_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for img_data, targets in val_loader:\n",
    "                img_data, targets = img_data.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "                outputs = model(img_data)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                val_predictions.extend(outputs.cpu().numpy())\n",
    "                val_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        # Get the current learning rate\n",
    "        current_lr = scheduler.get_last_lr()\n",
    "        \n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            best_epoch = epoch + 1\n",
    "            #early_stopping_counter = 0\n",
    "        #else:\n",
    "            #if epoch > warm_up_epochs:\n",
    "                #early_stopping_counter += 1\n",
    "                #if early_stopping_counter >= early_stopping_patience:\n",
    "                    #print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                    #break\n",
    "\n",
    "        train_mse = mean_squared_error(train_targets, train_predictions)\n",
    "        train_rmse = np.sqrt(train_mse)\n",
    "        val_mse = mean_squared_error(val_targets, val_predictions)\n",
    "        val_rmse = np.sqrt(val_mse)\n",
    "        train_r2 = r2_score(train_targets, train_predictions)\n",
    "        val_r2 = r2_score(val_targets, val_predictions)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_mse'].append(train_mse)\n",
    "        history['val_mse'].append(val_mse)\n",
    "        history['train_rmse'].append(train_rmse)\n",
    "        history['val_rmse'].append(val_rmse)\n",
    "        history['learning_rate'].append(current_lr)\n",
    "        history['epoch_time'].append(epoch_time)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    # Calculate and save metrics\n",
    "    train_metrics = calculate_metrics(model, train_loader, device)\n",
    "    val_metrics = calculate_metrics(model, val_loader, device)\n",
    "    test_metrics = calculate_metrics(model, test_loader, device)\n",
    "\n",
    "    metrics = {\n",
    "        'train_loss': train_metrics['loss'],\n",
    "        'train_mse': train_metrics['mse'],\n",
    "        'train_mae': train_metrics['mae'],\n",
    "        'train_rmse': train_metrics['rmse'],\n",
    "        'train_r2': train_metrics['r2'],\n",
    "        'val_loss': val_metrics['loss'],\n",
    "        'val_mse': val_metrics['mse'],\n",
    "        'val_mae': val_metrics['mae'],\n",
    "        'val_rmse': val_metrics['rmse'],\n",
    "        'val_r2': val_metrics['r2'],\n",
    "        'test_loss': test_metrics['loss'],\n",
    "        'test_mse': test_metrics['mse'],\n",
    "        'test_mae': test_metrics['mae'],\n",
    "        'test_rmse': test_metrics['rmse'],\n",
    "        'test_r2': test_metrics['r2'],\n",
    "        'min_lr': min_lr,\n",
    "        'max_lr': max_lr,\n",
    "        'total_time': total_time,\n",
    "        'average_epoch_time': sum(history['epoch_time']) / len(history['epoch_time'])\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTraining completed in {total_time:.2f} seconds\")\n",
    "    print(f\"Best model found at epoch {best_epoch}/{epochs}\")\n",
    "    print(f\"Best Train Loss: {history['train_loss'][best_epoch-1]:.4f}, Best Val Loss: {history['val_loss'][best_epoch-1]:.4f}\")\n",
    "    print(f\"Best Train MSE: {history['train_mse'][best_epoch-1]:.4f}, Best Val MSE: {history['val_mse'][best_epoch-1]:.4f}\")\n",
    "    print(f\"Best Train RMSE: {history['train_rmse'][best_epoch-1]:.4f}, Best Val RMSE: {history['val_rmse'][best_epoch-1]:.4f}\")\n",
    "\n",
    "    # Save figures for this fold\n",
    "    os.makedirs(f\"models/Regression/{dataset_name}/ViT/{model_name}\", exist_ok=True)\n",
    "    plot_metric(history['train_loss'], history['val_loss'], 'Loss', dataset_name, model_name)\n",
    "    plot_metric(history['train_mse'], history['val_mse'], 'MSE', dataset_name, model_name)\n",
    "    plot_metric(history['train_rmse'], history['val_rmse'], 'RMSE', dataset_name, model_name)\n",
    "    plot_learning_rate(history['learning_rate'], dataset_name, model_name)\n",
    "\n",
    "    # Save metrics to a file\n",
    "    os.makedirs(f'logs/Regression/{dataset_name}/ViT/{model_name}', exist_ok=True)\n",
    "    with open(f'logs/Regression/{dataset_name}/ViT/{model_name}/metrics.txt', 'w') as f:\n",
    "        for key, value in metrics.items():\n",
    "            f.write(f'{key}: {value}\\n')\n",
    "\n",
    "    # Save best model\n",
    "    model_save_path = f\"models/Regression/{dataset_name}/ViT/{model_name}/best_model.pth\"\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    torch.save(best_model, model_save_path)\n",
    "    print(f\"Best model saved to {model_save_path}\")\n",
    "            \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def calculate_metrics(model, data_loader, device):\n",
    "    model.eval()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img_data, targets in data_loader:\n",
    "            img_data, targets = img_data.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "            outputs = model(img_data)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "    all_targets = np.array(all_targets)\n",
    "    all_predictions = np.array(all_predictions)\n",
    "\n",
    "    mse = mean_squared_error(all_targets, all_predictions)\n",
    "    mae = mean_absolute_error(all_targets, all_predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(all_targets, all_predictions)\n",
    "\n",
    "    return {\n",
    "        'loss': total_loss / len(data_loader),\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2\n",
    "    }    \n",
    "\n",
    "def plot_metric(train_metric, val_metric, metric_name, dataset_name, model_name):\n",
    "    plt.figure()\n",
    "    plt.plot(train_metric, label=f'Train {metric_name}')\n",
    "    plt.plot(val_metric, label=f'Validation {metric_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend()\n",
    "    plt.title(f'{metric_name} vs. Epoch')\n",
    "    plt.savefig(f\"models/Regression/{dataset_name}/ViT/{model_name}/{metric_name.lower()}_plot.png\")\n",
    "    plt.close()\n",
    "\n",
    "def plot_learning_rate(learning_rates, dataset_name, model_name):\n",
    "    plt.figure()\n",
    "    plt.plot(learning_rates)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.title('Learning Rate vs. Epoch')\n",
    "    plt.savefig(f\"models/Regression/{dataset_name}/ViT/{model_name}/learning_rate_plot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_compile_and_fit(model, train_loader, val_loader, test_loader, dataset_name, model_name, batch_size=64, epochs=100, min_lr=1e-3, max_lr=1 , device='cuda', weight_decay=1e-2):\n",
    "    try:\n",
    "        if model is None:\n",
    "            print(f\"Model {model_name} is None\")\n",
    "            return None\n",
    "        else:\n",
    "            # Compile and fit the model\n",
    "            metrics = compile_and_fit(model, train_loader, val_loader, test_loader, dataset_name, model_name, epochs=epochs, min_lr=min_lr, max_lr=max_lr, device=device, weight_decay=weight_decay)\n",
    "            return metrics\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compile and fit {model_name}: {str(e)}\")\n",
    "        return None\n",
    "    finally:\n",
    "        # Clear CUDA cache and force garbage collection\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "def try_create_model(model_class, patch_size, imgs_shape):\n",
    "    try:\n",
    "        model = model_class(imgs_shape, patch_size)\n",
    "        \n",
    "        # Test the model with a sample input\n",
    "        sample_input = torch.randn(1, *imgs_shape)\n",
    "        output = model(sample_input)\n",
    "        \n",
    "        print(f\"Successfully created and tested {model_class.__name__}\")\n",
    "        \n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating or testing {model_class.__name__}: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch_lr_finder/lr_finder.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "def run_lr_finder(model_class, patch_size, attributes, imgs_shape, dataset_name, name, train_loader, val_loader, num_iter):\n",
    "\n",
    "    # Define the path where the plot will be saved\n",
    "    save_dir = os.path.join(f\"logs/Regression/{dataset_name}/ViT/{name}\")\n",
    "    save_path = os.path.join(save_dir, 'lr_finder_plot.png')\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if not os.path.exists(save_path):\n",
    "        # Create and train Model\n",
    "        model = try_create_model(model_class, patch_size, imgs_shape)\n",
    "        \n",
    "        if model is None:\n",
    "            return None\n",
    "        \n",
    "        # Move model to device\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = model.to(device)\n",
    "        \n",
    "        optimizer = optim.AdamW(model.parameters(), lr=1e-7, weight_decay=0.0001)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        lr_finder = LRFinder(model, optimizer, criterion, device=device)\n",
    "        lr_finder.range_test(train_loader, val_loader=val_loader, end_lr=1, num_iter=num_iter, step_mode=\"exp\")\n",
    "        \n",
    "        axis, lr = lr_finder.plot()\n",
    "        \n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Get the figure from the axis and save it\n",
    "        fig = axis.figure\n",
    "        fig.savefig(save_path)\n",
    "        print(f\"Plot saved to: {save_path}\")\n",
    "        \n",
    "        # Close the figure to ensure it's saved properly\n",
    "        plt.close(fig)\n",
    "        \n",
    "        lr_finder.reset()\n",
    "        print(f\"Suggested learning rate: {lr}\")\n",
    "        \n",
    "        return lr\n",
    "    else:\n",
    "        print(f\"LR finder plot already exists at {save_path}. Skipping LR finder process.\")\n",
    "        # Load and display the existing image\n",
    "        img = plt.imread(save_path)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')  # Turn off axis numbers and ticks\n",
    "        plt.title(\"Learning Rate Finder Plot\")\n",
    "        plt.show()\n",
    "        \n",
    "        return None  # Or you could return a default learning rate here\n",
    "\n",
    "# Usage example:\n",
    "# lr = run_lr_finder(Model1, attributes, imgs_shape, dataset_name, name, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "def zoom_image_nearest_neighbor(input_path, output_path, zoom_factor):\n",
    "    # Open the image\n",
    "    with Image.open(input_path) as img:\n",
    "        # Get the original size\n",
    "        width, height = img.size\n",
    "        \n",
    "        # Calculate the new size\n",
    "        new_width = int(width * zoom_factor)\n",
    "        new_height = int(height * zoom_factor)\n",
    "        \n",
    "        # Resize the image using nearest neighbor interpolation\n",
    "        resized_img = img.resize((new_width, new_height), Image.NEAREST)\n",
    "        \n",
    "        # Save the resized image\n",
    "        resized_img.save(output_path)\n",
    "\n",
    "def process_directory(input_dir, output_dir, zoom_factor):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate through all files in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, f\"{filename}\")\n",
    "            \n",
    "            zoom_image_nearest_neighbor(input_path, output_path, zoom_factor)\n",
    "            print(f\"Processed: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, blur=True, random_seed=SEED)\n",
    "#image_model = REFINED(problem= problem_type,hcIterations=5)\n",
    "#image_model = IGTD(problem= problem_type)\n",
    "#image_model = BarGraph(problem= problem_type)\n",
    "#image_model = DistanceMatrix(problem= problem_type)\n",
    "#image_model = Combination(problem= problem_type)\n",
    "#image_model = SuperTML(problem= problem_type)\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_TINTO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iterations_per_epoch(dataset_size, batch_size):\n",
    "    iterations = dataset_size // batch_size\n",
    "    if dataset_size % batch_size != 0:\n",
    "        iterations += 1\n",
    "    return iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = calculate_iterations_per_epoch(df.shape[0], batch_size)\n",
    "# For the Boston dataset, the number of samples is too small for a range test, so the number of epochs is tripled.\n",
    "#num_epochs = num_epochs*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EXPERIMENT 1: TINTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, blur=True, random_seed=SEED)\n",
    "name = f\"TINTO_blur\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=3e-4, max_lr=1.5e-2)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=8e-5, max_lr=1.5e-3)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, blur=True, option=\"maximum\", random_seed=SEED)\n",
    "name = f\"TINTO_blur_maximum\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=2e-4, max_lr=5e-3)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=5e-5, max_lr=1.5e-3)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = TINTO(problem= problem_type, random_seed=SEED)\n",
    "name = f\"TINTO\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=2e-4, max_lr=7e-3)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=7e-5, max_lr=1.5e-3)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EXPERIMENT 2: IGTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the dataframe\n",
    "num_columns = df.shape[1]\n",
    "\n",
    "# Calculate number of columns - 1\n",
    "columns_minus_one = num_columns - 1\n",
    "\n",
    "# Calculate the square root for image size\n",
    "import math\n",
    "image_size = math.ceil(math.sqrt(columns_minus_one))\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], fea_dist_method='Euclidean', image_dist_method='Euclidean', error='abs', max_step=30000, val_step=300, random_seed=SEED)\n",
    "name = f\"IGTD_{image_size}x{image_size}_fEuclidean_iEuclidean_abs\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are already generated\n",
      "HyNNImages/Regression/california_housing/images_california_housing_IGTD_3x3_fEuclidean_iEuclidean_abs/regression.csv\n",
      "Images shape:  (3, 3, 3)\n",
      "Attributes:  8\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created and tested Model1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c42c08dafa439d8c5d16d41e951d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 3.58E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to: logs/Regression/california_housing/ViT/IGTD_3x3_fEuclidean_iEuclidean_abs_Model1/lr_finder_plot.png\n",
      "Suggested learning rate: 0.0003583833511185672\n"
     ]
    }
   ],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created and tested Model1\n",
      "\n",
      "Training completed in 276.45 seconds\n",
      "Best model found at epoch 99/100\n",
      "Best Train Loss: 0.3354, Best Val Loss: 0.3663\n",
      "Best Train MSE: 0.3354, Best Val MSE: 0.3669\n",
      "Best Train RMSE: 0.5791, Best Val RMSE: 0.6057\n",
      "Best model saved to models/Regression/california_housing/ViT/IGTD_3x3_fEuclidean_iEuclidean_abs_Model1/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=1e-5, max_lr=4e-3)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created and tested Model2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec535ea2edbc48bb99e124275f44122e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 2.28E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAG1CAYAAADX6N+4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSEElEQVR4nO3dd3iT9d4/8Ped0Z2km7Z0QylltMwCArKXigwVf8gRUA6PAw8i4nrwQfCouBAOHg4qegQVD+AAOSqgyN57FgotpYO2dCedaZvcvz/SRkoLXWnvJH2/risXzZ07ySdfK3nzXbcgiqIIIiIiIiskk7oAIiIiojthUCEiIiKrxaBCREREVotBhYiIiKwWgwoRERFZLQYVIiIisloMKkRERGS1GFSIiIjIaimkLqA5jEYj0tPToVKpIAiC1OUQERFRA4iiiMLCQgQEBEAmu3ufiU0HlfT0dAQFBUldBhERETVBamoqAgMD73qOTQcVlUoFwPRB1Wq1xNUQERFRQ+h0OgQFBZm/x+/GpoNK9XCPWq1mUCEiIrIxDZm2wcm0REREZLUYVIiIiMhq2fTQDxFRW2QwGFBRUSF1GUR3pFQqIZfLLfJaDCpERDZCFEVkZmaioKBA6lKI6uXu7g4/P79mbx/CoEJEZCOqQ4qvry9cXFy4fxRZJVEUUVJSgqysLACAv79/s16PQYWIyAYYDAZzSPHy8pK6HKK7cnZ2BgBkZWXB19e3WcNAnExLRGQDquekuLi4SFwJUcNU/642dz4VgwoRkQ3hcA/ZCkv9rjKoEBERkdXiHBUiorbGaASuXQN0OkCtBsLDgXouDEckFf5mEhG1FYWFwPLlQMeOQEQE0Lu36c+ICGDFCtPjZPMWL16MHj16mO/PnDkTEydOlKye5mJQISJqC1JTTcHkxReB69drPpaUBMyfb3o8NbVVy7LlL1Fbqf0f//gH1q5da9HXvD0MtSQO/dThcGIu/rUnAXKZALkgQFb1p1xW/TPqOFb1syBALqv5uEImg1IhwEEug1Iug4PC9KdSbjr2533Tzw5y0/lKuelnR6UMzko5XBwUkMs4kY6IGqmwEBgxwhRIRLH249XHkpJM5508CTTgqrbUcsrLy+Hg4GCR19JoNBZ5HakwqNQhq7AM+6/mSF1GnRzkMjg7yKuCixxOVX/eeszZQQ6VkxJqJwXUzkqonZRQOyuq/jTdVzkp4OIg5woCorbgiy+AhIS6Q8qtKitN5/3738Dzz1vs7b///nssWbIECQkJcHFxQc+ePfHTTz/hgw8+wLp16wD8uUJk9+7dGDp0KFJTU/Hiiy/it99+g0wmw+DBg/GPf/wDoaGh5tf9/PPPsWzZMiQlJSE0NBRz587Fs88+CwC4fv06wsLC8J///AcrV67EqVOn0LFjR6xatQpDhgwxv8aFCxfw0ksvYf/+/XB1dcXo0aOxfPlyeHt7N7n22xUWFuLpp5/Gli1boFar8fLLL+Onn35Cjx49sGLFCgBAaGgoZs2ahatXr2LLli2YPHky1q5di1deeQWbN29GWloa/Pz8MG3aNCxatAhKpdL8+u+++y6WL1+OkpISTJkyBT4+PjXef+bMmSgoKMCWLVsAAEajEe+99x4+++wzZGZmolOnTvi///s/PPzwwwCAPXv2YNiwYdi5cydeeeUVxMXFoUePHvjyyy8RGRmJtWvXYsmSJTU++5dffomZM2c26veioRhU6tAr2AMfTYmBwSjCKIowGAGDKMJoFG85Jt5y7JbHbzmv+ucKo4hKgxHllUZUGESUG4yoMN83otwgmn+uMBhRUWlE+S3nl1UazH+/lBuMKC81Qlva/Ot8KGQCPFwd4OXqAC83B3i5OsLLzQHebo5Vx6ruuzrCV+0IJ6VlrttARK3IaARWrmzcc1auBP72N4tMsM3IyMDUqVPx/vvvY9KkSSgsLMT+/fshiiIWLFiAS5cuQafT4csvvwQAeHp6oqKiAmPGjMGAAQOwf/9+KBQKvPXWWxg7dizOnTsHBwcHrF+/HosWLcI///lP9OzZE6dPn8bs2bPh6uqKGTNmmN//pZdewooVK9ClSxd89NFHGD9+PJKSkuDl5YWCggIMHz4cf/3rX7F8+XKUlpbilVdewZQpU7Br164m1V6X+fPn4+DBg9i6dSvatWuHRYsW4dSpU7WGTj788EMsWrQIb7zxhvmYSqXC2rVrERAQgPPnz2P27NlQqVR4+eWXAQCbNm3C4sWLsWrVKgwaNAhff/01Vq5cifDw8Dv+N1m6dCm++eYbfPLJJ4iIiMC+ffvwl7/8BT4+PjVC3MKFC7Fs2TL4+Pjg6aefxpNPPomDBw/i0UcfxYULF7B9+3bs3LkTQMv22jCo1CHI0wVBntazqZIoitBXGlFabkBJhQGl5VW3CgNKyitv+dmAsgoDivUGFOkroCuthK6swnQrrURhWQV0ZZXQlVag0iii0igiu1CP7EJ9g+rwcFHCX+MMf40T/N2dzD/7aZwQ6O6C9h7OHJoisjbXrpmGdBpKFE3PuXbNNOm2mTIyMlBZWYnJkycjJCQEANC9e3fz487OztDr9fDz8zMf++abb2A0GvH555/X+Be7u7s79uzZg9GjR+ONN97AsmXLMHnyZABAWFgY4uLi8Omnn9YIKs899xweeughAMDq1auxfft2fPHFF3j55ZfNIeedd94xn//vf/8bQUFBuHLlCoqKihpd++0KCwuxbt06fPvttxgxYoT5swQEBNQ6d/jw4XjxxRdrHHv99dfNP4eGhmLBggXYsGGDOaisWLECs2bNwqxZswAAb731Fnbu3ImysrI669Hr9XjnnXewc+dODBgwAAAQHh6OAwcO4NNPP60RVN5++23z/VdffRX3338/ysrK4OzsDDc3NygUirt+dkthULEBgiDASWka5vGwwOuJoojSCgO0pRXIKy5HblE5cov1yC0qR05ROXKL9Mgt/vPPnCI9yiqMyC+pQH5JBeIydHW+roNchiBPZ4R5uyHcxxWhXq6IaOeGzn4qqJyUdT6HiFqYru7/X1vsebeJiYnBiBEj0L17d4wZMwajR4/Gww8/DA+PO/9tdvbsWSQkJEB12zyZsrIyJCYmori4GImJiZg1axZmz55tfryysrLWv+yrv4wBQKFQoE+fPrh06ZL5fXbv3g03N7daNSQmJmL06NGNrv12165dQ0VFBWJjY83HNBoNIiMja53bp0+fWsc2btyIlStXIjEx0Ryc1Gq1+fFLly7h6aefrvWZd+/eXWc9CQkJKCkpwahRo2ocLy8vR8+ePWsci46ONv9cfb2erKwsBAcH3+njtggGlTZIEAS4OCjg4qCAv8a53vNFUYSutBLp2lJkasv+/LOgDJm6UmQUlCGtoBTllUYkZhcjMbsYuFTzNUK9XNAlQI2uARp08VcjOlADLzfHFvqERGR2y5daqzzvNnK5HL///jsOHTqE3377DR9//DEWLlyIo0ePIiwsrM7nFBUVoXfv3li/fn2tx3x8fFBUVAQAWLNmDfr161fr/RqqqKgI48ePx3vvvVfrMX9//ybV3hyurq417h8+fBjTpk3DkiVLMGbMGGg0GmzYsAHLli1r8ntUt90vv/yC9u3b13jM0bHm38m3zoOp7tkyGo1Nfu+mYlChegmCAI2LEhoXJaL86/7Ly2AUkaEtRVJOMa7nFONaTjGScooRn1mIDG0ZrueW4HpuCX49n2l+Tri3K/qEeqBPiCf6hHogzNuVk3uJLC08HAgLMy1Jrm8yLQAIgun8u8xxaCxBEDBw4EAMHDgQixYtQkhICDZv3oz58+fDwcEBBoOhxvm9evXCxo0b4evrW6P3oJpGo0FAQACuXbuGadOm3fW9jxw5gnvvvReAqcfl5MmTeO6558zv88MPPyA0NBQKRd1fh42t/Xbh4eFQKpU4fvy4uSdCq9XiypUr5rru5NChQwgJCcHChQvNx5KTk2ucExUVhaNHj2L69Ok1PvOddOnSBY6OjkhJSakxzNNYDfnslsKgQhYhlwkI9HBBoIcLBkfUnHGeV1yOuHQd4jK0uJiuw4UbWiRmm8LMtZxibDqRBgDwcnVA/w5euDfCG4MjfBDgXn9vDxHVQyYD5s417ZPSUHPnWmyn2qNHj+KPP/7A6NGj4evri6NHjyI7OxtRUVEATPMuduzYgfj4eHh5eUGj0WDatGn44IMPMGHCBLz55psIDAxEcnIyfvzxR7z88ssIDAzEkiVLMHfuXGg0GowdOxZ6vR4nTpxAfn4+5t/yWVetWoWIiAhERUVh+fLlyM/Px5NPPgkAmDNnDtasWYOpU6fi5ZdfhqenJxISErBhwwZ8/vnnOHHiRKNrv7UXAjBNhp0xYwZeeukleHp6wtfXF2+88QZkMlm9/zCLiIhASkoKNmzYgL59++KXX37B5s2ba5zz/PPPY+bMmejTpw8GDhyI9evX4+LFi3ecTKtSqbBgwQK88MILMBqNGDRoELRaLQ4ePAi1Wl1jfs/dhIaGIikpCWfOnEFgYCBUKlWtHhmLEW2YVqsVAYharVbqUqiR8ov14h+XMsV3t10SH1l9SIxY+KsY8srPNW7DP9wtvvHTBfGPS5liib5S6pKJJFVaWirGxcWJpaWljX+yTieKERGiqFCIoqlfpe6bQiGKnTqZzreQuLg4ccyYMaKPj4/o6OgodurUSfz444/Nj2dlZYmjRo0S3dzcRADi7t27RVEUxYyMDHH69Omit7e36OjoKIaHh4uzZ8+u8ff9+vXrxR49eogODg6ih4eHeO+994o//vijKIqimJSUJAIQv/32WzE2NlZ0cHAQu3TpIu7atatGfVeuXBEnTZokuru7i87OzmLnzp3FefPmiUajscm1306n04mPPfaY6OLiIvr5+YkfffSRGBsbK7766qvmc0JCQsTly5fXeu5LL70kenl5iW5ubuKjjz4qLl++XNRoNDXOefvtt0Vvb2/Rzc1NnDFjhvjyyy+LMTEx5sdnzJghTpgwwXzfaDSKK1asECMjI0WlUin6+PiIY8aMEffu3SuKoiju3r1bBCDm5+ebn3P69GkRgJiUlCSKoiiWlZWJDz30kOju7i4CEL/88statd/td7Yx39+CKDakL9A66XQ6aDQaaLXaOrsHyXboKw04n6bF/qs52H81G2dSC2C85TfTWSnHvZ28MaarH0Z0bgeNCyfnUttSVlaGpKQkhIWFwcnJqfEvkJpq2swtIcF0/9a/+qv/ZR8RAezcCQQFNb9giVXvo3L69OlW20G1oYqLi9G+fXssW7bMvFrHHt3td7Yx398c+iGr4KiQo0+oJ/qEeuKFUZ2gLa3A4cQc7Luag73x2bhRUIodF29ix8WbUMgE9A/3wgPR/hjX3R8aZ4YWonoFBZl2nP3iC9M+KbcuWQ4LMw33PPkkd6RtAadPn8bly5cRGxsLrVaLN998EwAwYcIEiSuzDQwqZJU0zkqM7eaPsd38IYoiLqbrsONiJn67eBPxNwtxICEHBxJysGjrRYyM8sXEHu0xNNIXDgpevorojlQqYN48Uyjh1ZNb1Ycffoj4+Hg4ODigd+/e2L9/v3n3W7o7Dv2QzUnKKca2CxnYcvoGrtwsMh93d1Hi/u7+eKRPEGICNVxBRHal2UM/RK2MQz/UZoV5u+LZoR3xzJAOuJRRiC1nbuCnMzdwU6fH+qMpWH80BVH+akyNDcKEHu05NEREZMPYo0J2wWAUceRaLr4/mYZfzmegvNK0KZGTUob7uwdgamwQeod4sJeFbFb1v05DQ0Ph7Myl+2T9SktLzZOam9OjwqBCdkdbUoHNp9Pwn2OpiL9ZaD4e4euG/xcbjId7B7KXhWyOwWDAlStX4OvrCy8vL6nLIapXbm4usrKy0KlTp1o7BjOoEMG09f/p1AJsOJaC/57NQGmFaRdFZ6Uck3q1x/QBIejsx98bsh0ZGRkoKCiAr68vXFxc2ENIVkkURZSUlCArKwvu7u7m6wTdikGF6DaFZRXYciYd3xxOrtHL0i/MEzPuCcWoLu2glHPVA1k3URSRmZmJgoICqUshqpe7uzv8/PzqDNQ2FVRu3LiBV155Bdu2bUNJSQk6duyIL7/8ss6rSN6OQYUaSxRFHEvKw1eHk7H9YiYMVbvK+amd8Fi/YPy/2CD4qriigqybwWBARUWF1GUQ3ZFSqbzrBSJtJqjk5+ejZ8+eGDZsGJ555hn4+Pjg6tWr6NChAzp06FDv8xlUqDkytKX4z9EUfHssBTlF5QAApVzAfd39MX1AKHoFu7NrnYioBdhMUHn11Vdx8OBB7N+/v0nPZ1AhS9BXGrD9QibWHbqOUykF5uPd22sw455QPBDtDydlwy8dT0REd2czQaVLly4YM2YM0tLSsHfvXrRv3x7PPvssZs+eXef5er0eer3efF+n0yEoKIhBhSzmfJoW6w5fx9az6eYlzp6uDpgaG4Rp/UJ4RWciIguwmaBSva56/vz5eOSRR3D8+HE8//zz+OSTT+q81PTixYuxZMmSWscZVMjScov02HA8FeuPJCNdWwYAkMsEjO7SDjPuCUW/ME8OCxERNZHNBBUHBwf06dMHhw4dMh+bO3cujh8/jsOHD9c6nz0q1NoqDUbsvHQTaw9dx5Freebjnf1UmHFPKCb0CICLAzd4JiJqDJvZQt/f3x9dunSpcSwqKgo//PBDnec7OjrC0dGxNUojAgAo5DLzxREvZ+qw7lAytpy+gcuZhXjtx/NY+uslPNo3CI/3D0Wwl4vU5RIR2R1JN44YOHAg4uPjaxy7cuUKQkJCJKqI6M46+6mxdHJ3HHltBF6/PwrBni7QlVVizf4kDPlwN2atPY59V7Jhw1sTERFZHUmHfo4fP4577rkHS5YswZQpU3Ds2DHMnj0bn332GaZNm1bv87nqh6RkMIrYE5+FdYeTse9Ktvl4uI8rZgwIxeRe7aFy4lb9RES3s5k5KgDw888/47XXXsPVq1cRFhaG+fPn33HVz+0YVMhaJGYX4evDyfj+ZBqK9JUAADdHBcbHBODh3u3RK5gXRCQiqmZTQaU5GFTI2hTpK/HjqTSsO3QdidnF5uNh3q6Y3LM9JvVqj0APzmUhoraNQYVIYqIo4nBiLr4/lYbtFzJRUm4wP9Y/3BPjYwIwtqsfvNw4OZyI2h4GFSIrUqyvxPYLmfjhVBoOX8tF9f9xMgHoH+6F+7r7Y2w3P3gztBBRG8GgQmSlbhSUYuuZdPx6PgPnb2jNx2UCEBvmifu7+2NMNz9eGJGI7BqDCpENSMktwa8XMvDr+QycS/sztAgCEBvqifu6+2NcNz/4qhlaiMi+MKgQ2ZjUvBL8et4UWs7eFlr6hnjivu5+GNfdH+0YWojIDjCoENmw1LwSbL+QiV/OZ+BMaoH5uCAAfUI8MK6bP+7r7g8/DUMLEdkmBhUiO3GjoBTbqnpaTqUU1Hisd4iHeXiIV3UmIlvCoEJkh9ILSrHtQia2nc/AieT8Go/1DfXApJ6BuL+7PzQu3A2XiKwbgwqRncvUlmFb1UTcE8n55iXPDnIZRkT5YlLP9hga6QsHhaSX8yIiqhODClEbkqEtxU9n0rH51A3E3yw0H/dwUeKB6ABM7tUePYLcuYU/EVkNBhWiNkgURcRl6LD51A38dDYd2YV682NR/mr8pX8wJvRoDzdHhYRVEhExqBC1eZUGIw4m5mLzqTRsu5AJfaURAODqIMfEnu3xl/4hiPLn/zNEJA0GFSIyKygpxw+nbmD90WRcu+VCib1DPDB7cDhGdWkHuYzDQkTUehhUiKgWURRx+Fou1h9NwY4Lmag0mv7XD/N2xaxBYXi4dyCclHKJqySitoBBhYjuKquwDF8dSsbXR5KhLa0AAHi5OuCZoR3wl/4hDCxE1KIYVIioQYr1ldh4PBVfHEjCjYJSAEA7tSOeGx6BR/sEcXkzEbUIBhUiapQKgxE/nkrDyj8SzIEl3McVb4zviiGdfCSujojsDYMKETWJvtKAjcdTsfKPq8gpKgcAjIxqh0UPdEGwl4vE1RGRvWjM9zf7dYnIzFEhx/QBodi1YCj+OigMCpmAnZduYvSKvfjyYBKMRpv9dw0R2SgGFSKqRe2kxOsPdMH2eYNxTwcvlFUYseS/cZi65ghS80qkLo+I2hAGFSK6o46+Kqz/az/8fWI3uDjIcTQpD2NW7MOW0zekLo2I2ggGFSK6K0EQ8Hj/EGx//l7EhnmipNyAeRvPYOHm8yirMEhdHhHZOQYVImqQYC8X/Gd2fzw/IgKCAKw/moJHPztS45pCRESWxqBCRA0mlwl4YVQnrHsiFh4uSpxNLcDk1QeRmF0kdWlEZKcYVIio0e7t5IMfnx2IEC8XpOaV4qHVh3AurUDqsojIDjGoEFGThHm74odn7kGPIHcUlFTg8S+O4WK6VuqyiMjOMKgQUZN5uznim7/2Q69gd2hLTWElPrNQ6rKIyI4wqBBRs7g5KrD2yVjEBGqQV1yOx784ikxtmdRlEZGdYFAhomZTOynx1ZP90KmdG7IK9fjrV8dRUl4pdVlEZAcYVIjIIjQuSnwxoy+8XB1w4YYO8zee5Zb7RNRsDCpEZDFBni749PHecJDLsP1iJlbtTpC6JCKycQwqRGRRfUI98dakbgCA5Tuv4FhSnsQVEZEtY1AhIoub0icIk3u2h1EE5v7nNPKKy6UuiYhsFIMKEbWIv0/shnBvV2TqyvDy92chipyvQkSNx6BCRC3C1VGBjx/rCQe5DDsvZeH7k2lSl0RENohBhYhaTNcADV4Y1QkA8OZ/45ChLZW4IiKyNQwqRNSiZg8OQ0yQOwr1lXj1h/McAiKiRmFQIaIWpZDLsOyRaDgoZNh7JZtDQETUKAwqRNTiOvqq8MJI0xDQO79eQj5XARFRAzGoEFGr+OvgMES2UyG/pALvbb8sdTlEZCMYVIioVSjlMvNGcBuOp+LEdW4ER0T1Y1AholbTN9QTU/oEAgBe33IBlQajxBURkbVjUCGiVvXquCi4uyhxObMQG0+kSl0OEVk5BhUialWerg54fkQEAOCj366gsKxC4oqIyJoxqBBRq/tL/xCEe7sit7gcq3YnSl0OEVkxBhUianVKuQz/e18UAODfB5KQmlcicUVEZK0YVIhIEiOifHFPBy+UG4x4l8uViegOGFSISBKCIOD1+7tAEIBfzmXgZHK+1CURkRViUCEiyXQJUOPhXqblyst+i5e4GiKyRpIGlcWLF0MQhBq3zp07S1kSEbWy50dGQCkXcCgxF4cSc6Quh4isjOQ9Kl27dkVGRob5duDAAalLIqJWFOjhgqmxwQBMy5V5dWUiupXkQUWhUMDPz8988/b2lrokImplc4Z1hKNChhPJ+dh7JVvqcojIikgeVK5evYqAgACEh4dj2rRpSElJueO5er0eOp2uxo2IbF87tROmDwgBACz/nb0qRPQnSYNKv379sHbtWmzfvh2rV69GUlISBg8ejMLCwjrPX7p0KTQajfkWFBTUyhUTUUt5akgHOCllOJumxaHEXKnLISIrIYhW9E+XgoIChISE4KOPPsKsWbNqPa7X66HX6833dTodgoKCoNVqoVarW7NUImoBi7dexNpD1zGooze++Ws/qcshohai0+mg0Wga9P0t+dDPrdzd3dGpUyckJCTU+bijoyPUanWNGxHZj78ODoNcJuBAQg7OpRVIXQ4RWQGrCipFRUVITEyEv7+/1KUQkQQCPVwwISYAAPDJXl4DiIgkDioLFizA3r17cf36dRw6dAiTJk2CXC7H1KlTpSyLiCT01JAOAIBtFzJxLbtI4mqISGqSBpW0tDRMnToVkZGRmDJlCry8vHDkyBH4+PhIWRYRSSjST4URnX0hisDaQ9elLoeIJKaQ8s03bNgg5dsTkZV6YmAY/richR9OpuGlMZFQOSmlLomIJGJVc1SIiABgYEcvdPR1Q3G5Ad+fTJO6HCKSEIMKEVkdQRAw455QAMBXh5NhNFrNLgpE1MoYVIjIKk3u2R4qJwWScoqx7yq31SdqqxhUiMgquToq8Ehv0+7T6ziplqjNYlAhIqtVff2fPVeykV5QKnE1RCQFBhUislqh3q7oH+4JUQQn1RK1UQwqRGTVpvQxDf9sOpHKSbVEbRCDChFZtXHd/KFyVCAtvxSHr/GqykRtDYMKEVk1Zwc5Huxhuv7PphOpEldDRK2NQYWIrN6jfU3DP9suZEJbUiFxNUTUmhhUiMjqdW+vQWc/Fcorjdh6Ll3qcoioFTGoEJHVEwQBD/UKBAD89wyDClFbwqBCRDbhgRh/CAJw7Hoe91QhakMYVIjIJvhrnNE31BMA8DOHf4jaDAYVIrIZ42NMq3+2nmVQIWorGFSIyGbc180PcpmACzd0uJZdJHU5RNQKGFSIyGZ4uTliUEdvAOxVIWorGFSIyKY8WDX8818GFaI2gUGFiGzK6K7toJQLSMwuRiKHf4jsHoMKEdkUlZMS/cO9AAC/x92UuBoiamkMKkRkc0Z3aQeAQYWoLWBQISKbM7IqqJxKyUdOkV7iaoioJTGoEJHN8dc4o1t7NUQR2HUpS+pyiKgFMagQkU0aFeUHAPiNwz9Edo1BhYhs0qiq4Z8DCdkoLTdIXA0RtRQGFSKySVH+KrR3d0ZZhRH7r2ZLXQ4RtRAGFSKySYIgYGSULwBgH4MKkd1iUCEimzU4wgcAsP9qjsSVEFFLYVAhIpvVv4MXFDIBybklSM4tlrocImoBDCpEZLPcHBXoFeIBgL0qRPaKQYWIbNq9EaarKXNCLZF9YlAhIptWPU/lUEIuKg1GiashIktjUCEim9atvQbuLkoU6itxNq1A6nKIyMIYVIjIpsllAgZ2NA3/7LvCeSpE9oZBhYhsXvU8Fe6nQmR/GFSIyOYNqpqnci5NiyJ9pcTVEJElMagQkc1r7+6MQA9nGIwiTibnS10OEVkQgwoR2YV+YV4AgGNJuRJXQkSWxKBCRHahX5gnAODotTyJKyEiS2JQISK70C/cFFTOphWgrMIgcTVEZCkMKkRkF4I9XeCndkKFQcSpFM5TIbIXDCpEZBcEQUBs1fDPsSQO/xDZCwYVIrIb1cM/nKdCZD8YVIjIblRPqD2Vko/ySl73h8geMKgQkd3o4OMGbzcH6CuNOMfr/hDZBQYVIrIbgiCgb2jVPJXrHP4hsgcMKkRkV3qHeAAATqcUSFsIEVkEgwoR2ZWewe4ATEFFFEVpiyGiZrOaoPLuu+9CEATMmzdP6lKIyIZ1DdBAKReQU6RHWn6p1OUQUTNZRVA5fvw4Pv30U0RHR0tdChHZOCelHF381QCA06kF0hZDRM0meVApKirCtGnTsGbNGnh4eEhdDhHZgZ7B1fNUuEMtka2TPKjMmTMH999/P0aOHFnvuXq9HjqdrsaNiOh2t85TISLbppDyzTds2IBTp07h+PHjDTp/6dKlWLJkSQtXRUS2rmeQqUclLl0HfaUBjgq5xBURUVNJ1qOSmpqK559/HuvXr4eTk1ODnvPaa69Bq9Wab6mpqS1cJRHZoiBPZ3i5OqDcYMTFdPa8EtkyyYLKyZMnkZWVhV69ekGhUEChUGDv3r1YuXIlFAoFDIbal2l3dHSEWq2ucSMiup0gCBz+IbITkg39jBgxAufPn69x7IknnkDnzp3xyiuvQC5nVy0RNV3PYA/svJRVNaE2TOpyiKiJJAsqKpUK3bp1q3HM1dUVXl5etY4TETVWzyB3AOxRIbJ1kq/6ISJqCd0DNQCAGwWlyC3SS1wNETWVpKt+brdnzx6pSyAiO6FyUiLc2xXXcopx/oYWQyN9pS6JiJqAPSpEZLe6tTf1qly4oZW4EiJqKgYVIrJb3auCynkGFSKbxaBCRHarep7KhRvcS4XIVjGoEJHd6hpg2mvpRkEp8orLJa6GiJqCQYWI7Fb1hFqAwz9EtopBhYjsGifUEtk2BhUismvVE2rPpRVIWwgRNQmDChHZtT97VDihlsgWMagQkV3r2p4TaolsGYMKEdk1tZMSYZxQS2SzmhRUUlNTkZaWZr5/7NgxzJs3D5999pnFCiMishROqCWyXU0KKo899hh2794NAMjMzMSoUaNw7NgxLFy4EG+++aZFCyQiaq4u/qbhn0sZnKdCZGuaFFQuXLiA2NhYAMCmTZvQrVs3HDp0COvXr8fatWstWR8RUbNF+asAMKgQ2aImBZWKigo4OjoCAHbu3IkHH3wQANC5c2dkZGRYrjoiIguo7lFJyilGablB4mqIqDGaFFS6du2KTz75BPv378fvv/+OsWPHAgDS09Ph5eVl0QKJiJrLR+UIL1cHGEUg/mah1OUQUSM0Kai89957+PTTTzF06FBMnToVMTExAICtW7eah4SIiKyFIAiI4jwVIpukaMqThg4dipycHOh0Onh4eJiP/8///A9cXFwsVhwRkaVE+atwICGHQYXIxjSpR6W0tBR6vd4cUpKTk7FixQrEx8fD19fXogUSEVlClwD2qBDZoiYFlQkTJuCrr74CABQUFKBfv35YtmwZJk6ciNWrV1u0QCIiS6ge+rmcUQhRFCWuhogaqklB5dSpUxg8eDAA4Pvvv0e7du2QnJyMr776CitXrrRogUREltDBxw0OchkK9ZVIyy+VuhwiaqAmBZWSkhKoVKZ9CX777TdMnjwZMpkM/fv3R3JyskULJCKyBKVcho6+bgCAOA7/ENmMJgWVjh07YsuWLUhNTcWOHTswevRoAEBWVhbUarVFCyQishSu/CGyPU0KKosWLcKCBQsQGhqK2NhYDBgwAICpd6Vnz54WLZCIyFK4Qy2R7WnS8uSHH34YgwYNQkZGhnkPFQAYMWIEJk2aZLHiiIgs6c9r/nDTNyJb0aSgAgB+fn7w8/MzX0U5MDCQm70RkVWrHvpJyStBYVkFVE5KiSsiovo0aejHaDTizTffhEajQUhICEJCQuDu7o6///3vMBqNlq6RiMgiPFwd4Kd2AgDEZ7JXhcgWNKlHZeHChfjiiy/w7rvvYuDAgQCAAwcOYPHixSgrK8Pbb79t0SKJiCwlyl+FTF0Z4jJ06BPqKXU5RFSPJgWVdevW4fPPPzdfNRkAoqOj0b59ezz77LMMKkRktaL81dgdn80JtUQ2oklDP3l5eejcuXOt4507d0ZeXl6ziyIiainV81TiOKGWyCY0KajExMTgn//8Z63j//znPxEdHd3sooiIWkp1ULmSWQijkVvpE1m7Jg39vP/++7j//vuxc+dO8x4qhw8fRmpqKn799VeLFkhEZEmhXi5wUMhQWmFASl4JQr1dpS6JiO6iST0qQ4YMwZUrVzBp0iQUFBSgoKAAkydPxsWLF/H1119bukYiIotRyGXo1M60lf5lrvwhsnqCaMHLiJ49exa9evWCwWCw1EvelU6ng0ajgVar5db9RNRgC747i+9PpmHeyAjMG9lJ6nKI2pzGfH83qUeFiMiWdfYzbaXPvVSIrB+DChG1OZ39TP+C49APkfVjUCGiNieyqkflem4xSsorJa6GiO6mUat+Jk+efNfHCwoKmlMLEVGr8FE5wsdFAZcbKUjbeRCdOrUHwsMBGf/tRmRtGhVUNBpNvY9Pnz69WQUREbWowkLg88/xy8cfwjcnHfis6nh4OPC3vwGzZgEqlaQlEtGfLLrqp7Vx1Q8RNUpqKjBiBJCQAFEEBNzy158gmP7s2BH44w8gKEiaGonaAK76ISK6XWGhKaQkJQGiWDOkAIAomm5JSabzCjnRlsgaMKgQUdvwxRdAQgJQWc/k2cpK03n//nfr1EVEd8WgQkT2z2gEVq5s3HNWrjQ9j4gkxaBCRPbv2jXzkE+DiKLpOdeutWxdRFQvBhUisn86Xes+j8iGlVUYoCurkLoMMwYVIrJ/TV0VyNWE1MakF5Ri1PK96PPWTnx9JFnqcgAwqBBRWxAeDoSF/bkEuT6CYHpOeHjL1kVkRURRxJxvTyE1rxTllUYs3noRecXlUpfFoEJEbYBMBsyd27jnzJ3LnWqpTfk97iZOpxTAWSmHi4McBqOInXE3pS6LQYWI2ohZs0ybuSnq2ZBboQAiIoAnn2yduoisxCd7EwEATwwMxTNDOgAAtl/MlLIkABIHldWrVyM6OhpqtRpqtRoDBgzAtm3bpCyJiOyVSmXacbZ6COi2YSCx+lh4OLBzJ7fRpzblwg0tTqUUQCkXMHNgKIZE+gAATqfkQ+oN7CUNKoGBgXj33Xdx8uRJnDhxAsOHD8eECRNw8eJFKcsiInsVFAScPAl89BEQGlrjIW27QGD5cuDECW6fT23O14dNE2fHdvOHr8oJndqpIBOA/JIKZBXqJa2tURcltLTx48fXuP/2229j9erVOHLkCLp27SpRVURk11QqYN480xyUa9fw84HL+OBwBiL6RePzJ/tJXR1Rq9OWVOCnszcAANMHhAAAnJRyhPu4ISGrCHEZOrRTO0lWn6RB5VYGgwHfffcdiouLMWDAgDrP0ev10Ov/THY67nFARE0lkwEdO8JH5oHky0dQmVUsdUVEkjiSlIuyCiM6+LiiT4iH+XiUvxoJWUW4lKHDsEhfyeqTfDLt+fPn4ebmBkdHRzz99NPYvHkzunTpUue5S5cuhUajMd+C2D1LRM3U2c+0V8qNglKr2uSKqLXkFJk6AMK83SDcMncryt80T+tyhrQX6JQ8qERGRuLMmTM4evQonnnmGcyYMQNxcXF1nvvaa69Bq9Wab6mpqa1cLRHZG42LEv4aU7f2lUxeMZnanrwi014pXq4ONY73DvbAuG5+6BfuKUVZZpIP/Tg4OKBjx44AgN69e+P48eP4xz/+gU8//bTWuY6OjnB0dGztEonIznX2UyFDW4ZLmYXoEyrtX8pErS23alM3T7eaQaVfuBf6hXtJUVINkveo3M5oNNaYh0JE1NIiq4Z/Lmdw3hu1PdW7z97eo2ItJO1Ree211zBu3DgEBwejsLAQ3377Lfbs2YMdO3ZIWRYRtTHVY/HxHPqhNii32NQ54OXGoFJLVlYWpk+fjoyMDGg0GkRHR2PHjh0YNWqUlGURURtTPaE2PrMQoijWmFBIZO9yq+aoeLpa59QKSYPKF198IeXbExEBAMJ9XKGUCyjUV+JGQSkCPVykLomo1Vj70I/VzVEhImptSrkMHXzcAEi/FJOoNYmiiPySqqBipUM/DCpERDCt/AGA+JsMKtR26MoqUWEwXcvHkz0qRETWq7O/aZ7KJa78oTYkv2rYx9VBDkeFXOJq6sagQkQEINKPK3+o7SkurwQAuDlJvq3aHTGoEBEBiKpa+XMtpxhlFQaJqyFqHSXlpt91FwcGFSIiq9ZO7QiNsxIGo4iErCKpyyFqFcV6U4+Ki4N1DvsADCpERAAAQRD+nFDL4R9qI6p7VFzZo0JEZP2iqibUxnFCLbUR5h4VR/aoEBFZvS4BpqBy4YZW4kqIWgd7VIiIbEj39hoAwMV0HYxGUeJqiFpedVBx5hwVIiLrF+HrBkeFDEX6SlzPLZa6HKIWV1K1PNmVQYWIyPop5DLzPJXzHP6hNqBYX7U82ZFDP0RENqF6+IfzVKgtYI8KEZGNqQ4q7FGhtqCYG74REdmWbtUTam9wQi3ZvxJu+EZEZFsi2pkm1BZyQi21AeYt9DlHhYjINijlMnSt2k/lTGqBtMUQtYCCknJ8sjcRcek6zlEhIrJFvYI9AACnUvIlroTIckRRxJFruXjz5zi8u+0y7v94P86mmeZiWfMcFeutjIhIIr1CPIADSTiVXCB1KUQW8/qWC1h/NMV8X7xlCpYrt9AnIrId1T0qlzN15muhENmy3CJ9jZACAP3DPc0/czItEZEN8dM4ob27M4wicJbzVMgOXEyvfaHN18ZFmX9WOylbs5xG4dAPEVEdega740ZBKU6l5OOejt5Sl0PULBfSa+8LFB2owbJHYqAtrYCv2kmCqhqGPSpERHX4c0JtgbSFEFnAxRumHpUIXzcAQKiXCwRBwEO9A/HkoDApS6sXe1SIiOrQO8QUVE4m58NoFCGTCRJXRNR0lzJMQWXR+C4o1hsQHaiRuKKGY1AhIqpD1wA13BwV0JZWIC5DZ96xlsjWGI0i0vJLAQChXq4I8nSRuKLG4dAPEVEdFHIZYsNMqyIOJ+ZKXA1R02UX6VFuMEIuE+Cvsd65KHfCoEJEdAf3dPACABxKzJG4EqKmS8svAQD4a5ygkNve177tVUxE1EoGVAWVY0l5qDAYJa6GqGmqh30CPZwlrqRpGFSIiO4gyk8NdxclissNOH+j9vJOIlvwZ1Cxrbkp1RhUiIjuQCYT0D+savgngcM/ZJuqh37Yo0JEZIcGRZg2e9sTny1xJURNc6OgDAAQ4M6gQkRkd4Z39gVgupJyXnG5xNUQNV6WzhRUfFWOElfSNAwqRER3EeDujCh/NYwisPdKltTlEDVadqEeAOCrsr2lyQCDChFRvUZU9ar8cYlBhWxLhcGI3KqeQF81e1SIiOzS8ChTUNl7JZvLlMmm5BSZelMUMgGeLg4SV9M0DCpERPWICXSHl6sDCssqcSwpT+pyiBosS2cKKt5ujjZ7vSoGFSKieshlAkZ1aQcA+OV8hsTVEDVcVvX8FBsd9gEYVIiIGuT+aH8AwI4Lmajk8A/ZiKxC217xAzCoEBE1yIBwL3i4KJFbXI6jHP4hG1E99ONjoyt+AAYVIqIGUchlGNvNDwDw8zkO/5BtMA/9sEeFiMj+3d89AACw4yKHf8g2ZFcP/XCOChGR/esf7glPVwfkFZfjyDUO/5D1y7Lxzd4ABhUiogZTyGUY09U0/PPL+XSJqyGqX/UcFQ79EBG1EQ9Urf7ZztU/ZOWMRtG84RuHfoiI2oh+Yabhn/ySChy+lit1OUR3lFdSjkqjCEEwbfhmqxhUiIga4dbVP/89y+Efsl7Vwz6eLg5Qym336952KyciksiDMabVP9vOZ6KswiBxNUR1q97szceG56cADCpERI0WG+qJ9u7OKNRX8orKZLX+3D7fdlf8ABIHlaVLl6Jv375QqVTw9fXFxIkTER8fL2VJRET1kskETOhh6lXZfPqGxNUQ1S3bDjZ7AyQOKnv37sWcOXNw5MgR/P7776ioqMDo0aNRXFwsZVlERPWa1LM9AGBPfBbyisslroaotiyd7V/nBwAUUr759u3ba9xfu3YtfH19cfLkSdx7770SVUVEVL+Idip0DVDjYroOv5xLx+MDQqUuiagGe9g+H7CyOSparRYA4OnpWefjer0eOp2uxo2ISCrVvSoc/iFrxDkqFmY0GjFv3jwMHDgQ3bp1q/OcpUuXQqPRmG9BQUGtXCUR0Z8ejAmATABOpRQgIatI6nKIaqhe9cMeFQuZM2cOLly4gA0bNtzxnNdeew1ardZ8S01NbcUKiYhq8lU7YXjndgCA9UeTJa6G6E+iKJr3UWnHHpXme+655/Dzzz9j9+7dCAwMvON5jo6OUKvVNW5ERFL6S/9gAMD3J9NQUl4pcTVEJrqySugrTZd44D4qzSCKIp577jls3rwZu3btQlhYmJTlEBE12r0RPgj2dEFhWSW2nuFOtWQdqlf8qJ0UcFLKJa6meSQNKnPmzME333yDb7/9FiqVCpmZmcjMzERpaamUZRERNZhMJph7Vb46nAxRFCWuiAg4f8O0OCXcx03iSppP0qCyevVqaLVaDB06FP7+/ubbxo0bpSyLiKhRHukdBAeFDHEZOpxOLZC6HCIcS8oDYLqIpq2TdB8V/suDiOyBh6sDxkcH4IdTafjy4HX0CvaQuiRq46qDSt9Q2w8qVjGZlojI1j05KBQA8Mu5dCTlcHdtkk5puQHXqn4He4XYfmhmUCEisoCuARoM7+wLowis3pMgdTnUhhWWVQAABAHwcFFKXE3zMagQEVnInGEdAQA/nrqBtPwSiauhtqpIb1om7+aggCAIElfTfAwqREQW0jvEAwM7eqHSKOLTvdekLofaqGK9AQDg6ijpNFSLYVAhIrKg6l6VjSdSkaktk7gaaosK9aahHzcnBhUiIrrNgHAv9A31QHmlESt3XZW6HGqD2KNCRER3JAgCXhrTGQCw6XgqrnMFELWy4uo5Ko62vSNtNQYVIiILiw3zxNBIH1QaRXz0+xWpy6E2ptAcVNijQkREd7BgdCQAYOvZdMSl6ySuhtqS6h4VDv0QEdEddWuvwQPR/gCApdsucSduajXF7FEhIqKGeGlMJBzkMuy/moOdl7KkLofaiCIGFSIiaogQL1fMGhwGAPj7z3EoqzBIXBG1BUVlHPohIqIGem5YR7RTOyIlrwRfHEiSuhxqA4rLTUFFxX1UiIioPq6OCrw6zrRcedXuBG4CRy2uqHofFQcGFSIiaoCJPdqjV7A7SsoNeG/7ZanLITtXVHVRQg79EBFRgwiCgMUPdoUgAJtP38DJ5DypSyI7daOgFKdSCgBw6IeIiBohOtAdU3oHAQAWb42D0cjlymR5b/73ovlnT1cHCSuxHAYVIqJW8tLYSKgcFTh/Q4vvT6ZJXQ7ZofjMQgDA6C7t0NlPJXE1lsGgQkTUSrzdHPH8yAgAwPs7LqOwai4BkSVUGIxIzS8FACyZ0BWCIEhckWUwqBARtaLpA0IR7uOKnKJyrN6TKHU5ZEdu5JfCYBThpJShncpJ6nIshkGFiKgVOShkeG1cFABg7aHryCsul7gishdJuaYrdYd4ukIms4/eFIBBhYio1Y2M8kX39hqUlBvw6T72qpBlJOeYgkqot4vElVgWgwoRUSsTBAEvjDLNVfnqUDJyivQSV0T2ICXPND8lxMtV4kosi0GFiEgCwyJ9ERPkjtIKAz7dy14Var7sqsDrq3KUuBLLYlAhIpKAIAh4oWoF0FeHk5Gl49b61Dw5haag4sOgQkREljCkkw96BrtDX2nEx7sSpC6HbFx1j4qPG4MKERFZgCAIeHFUJADg6yPJWH80WeKKyJZVz3XyZo8KERFZyqAIb8wd3hEAsGRrHC5n6iSuiGxReaURBSWmDQS92aNCRESW9MKoThgZ5YtygxEf7oiXuhyyQbnFpt4UhUyAu7NS4mosi0GFiEhigiBg4f1dIAjAzktZuHqzUOqSyMbkFJo2DvRyc7Crzd4ABhUiIqsQ5u2KMV38AACf7bsmcTVka6rnp9jbih+AQYWIyGr8z5BwAMCWMzeQoS2VuBqyJdUrfuxtfgrAoEJEZDV6BXsgNswTFQYRn/CChdQI+VXXjPJ0cZC4EstjUCEisiLzRpg2gfvPsVRkarkJHDVMftWKH3cGFSIiakkDOnghNtQT5QYjVu/hJnDUMOYeFVf7WvEDMKgQEVkVQRAwr2pr/f8cT+XW+tQg+SWmoMIeFSIianEDOnihV7A7yiuN+PxAktTlkA2oDiqergwqRETUwgRBwHNVu9V+cyTZ3K1PdCd/zlHh0A8REbWCYZG+6OKvRkm5AV8eui51OWTlCqp6VDw49ENERK1BEATMGWbqVVl7MAmFZRUSV0TWShRFc48Kh36IiKjVjO3mh3AfV+jKKvHNkRSpyyErpSurhMEoAuDQDxERtSK5TMCzQ029Kl8cuIbScoPEFZE1qh72cXGQw1Ehl7gay2NQISKyYhN6BCDQwxk5ReX490GuAKLa8ortd34KwKBCRGTVlHIZXhoTCQBYtTsBCVm8sjLVVFA1P8XDDjd7AxhUiIis3vjoAPQP90RJuQGzvzoJbSkn1tKf2KNCRESSkskE/POxXgjQOCEppxhz/3PaPHmSKN+OlyYDDCpERDbB280Rn03vAyelDHuvZOPtXy5BFBlW6JahHztc8QMwqBAR2Yxu7TV4/+EYAMC/DybhuxNpEldE1iDPjq/zAzCoEBHZlAdjArBgdCcAwN9/ieNFC8m8PNkeN3sDJA4q+/btw/jx4xEQEABBELBlyxYpyyEisglPD+mA6EANCssqseini1KX0yacTS3A/3x1Aj+duYEifaXU5dSQX2y/1/kBJA4qxcXFiImJwapVq6Qsg4jIpijkMrw7ORoKmYDtFzOx/UKG1CXZvXe3XcZvcTfx/IYz6PX33/H6lvNWswGfvU+mVUj55uPGjcO4ceOkLIGIyCZ1CVDjqSHhWLU7EU9/cwqju7TD/NGd0NlPLXVpNqeswoAdFzMhlwm4v7s/BEEwPyaKIvbEZ+PwtVzzsfJKI745koLjSfmYP7oTRnT2hUIu3b/78+186EfSoNJYer0eer3efF+n00lYDRGRtP42PAK7LmfjUoYOv8XdxG9xNxHlr0a/ME+8Oq4znJT2t516S3jmm5PYHZ8NAPgmPBljuvphTFc/qJ2V+OZIMt7ddhkA0NHXDb+/cC/2X83B/E1nEX+zEE99fRJR/mpM7BGAGfeEtnqb33pBQnsd+rGpoLJ06VIsWbJE6jKIiKyCk1KONdN744WNZ3D8ej4A4FKGDpcydDibVoDX749C7xBPiau0bvGZheaQAgBHruXhyLU8LPlvXK1zpw8IgSAIuLeTD36ZOwj/3JWA706mmtt8y5l0fDy1Jzr6urVa/SXlBpRXGgHY79CPIFrJQnxBELB582ZMnDjxjufU1aMSFBQErVYLtZrdnUTUdiXnFuP7k2mQCQL+tScBFQYRSrmAVY/1wuiuflKXZ7Xe/G8c/n0wCWO7+mHh/VHYdCIVv8fdxOVM06UKBAGYOzwC80ZG1BgSqpaYXYTNp27g22MpyCsuh9pJgS9m9kXf0NYJiNeyizB82V64OshxYcmYOmu0RjqdDhqNpkHf3zYVVG7XmA9KRNRWJGQV4t1t8dh56SYAoL27Mz75S28Ul1fiXFoBegZ7wN1ZCbWzEu3UThJXKx1RFHHvB7uRmleKzx7vbQ50RqOI3OJy6MoqUGkQEemnqve1snRleGb9KZxMzoejQoZVj/XCyC7tWvoj4FBiDh5bcxThPq7Y9eLQFn8/S2nM97dNDf0QEVH9Ovqq8MlfeuGJtcex/2oObhSUYvw/D9Q6TyYA80d1wrNDO0Ims41/iVvS9dwSpOaVQikXMLCjt/m4TCbAR+UIH5Vjg1/LV+2Eb2b1w3PfnsIfl7Pw1Dcn8bfhHfG34RGQt2Db3qzaR8fPjgOnpEGlqKgICQkJ5vtJSUk4c+YMPD09ERwcLGFlRES2TSGXYc30PthxMRPLf7+C67klUMoFdPRV4crNQjgr5SjSV+LD365g69l0PHVvB0zu1d5mhg4sYfMp086+fUM94erY/K9DZwc5Pnm8NxZuPo9NJ9KwYudV/HIuA1H+alQYjDiXpoXKSYFXxnbG4Ahvi6wUytDaf1CRdOhnz549GDZsWK3jM2bMwNq1a+t9Pod+iIjqZzCKuJpVCE9XB/iqnGAwipDLBHx3IhWLfrqI0grTfiATegTg7xO7Qe1kn6tHbnU6JR+TVx+CKAIfPhKDh3sHWvT1N59Ow6s/nIe+aqLr7cJ9XPHhIzHoGeTerHD4xk8XsO5wMp4d2gEvj+3c5NdpbTYz9DN06FBeVIuIqIXJZUKN/VWqhyIe6ROEkVHt8O2xFCz//Qp+OpOO3Zez8MzQjvife8NbdMhCalvPpkMUgfu6++GhXu0t/vqTegYi1MsVL246iwB3ZwS4O+FYUh7KK43IKS7HtexiTP7XIXT2U2HuiAj0C/OEi4MCTkpZo4JLZvXQj8Z+e1Q4R4WIqA3zcHXAnGEd0TPYHYt+uoiErCK8t/0y9l3Jxor/18MuJ9uKoohdl7MAAA/GtNxwV89gD+xaMLTW8exCPd759RJ+OZ+By5mFeHb9qRqPa5yVGBbpgwk92mNQhDeUdxkiyqwa+rHH/07VeFFCIiLCPR28sWPevXj/oWi4OMhx+FouRizbi7d+jkNCVqHU5VnUtZxiJFfN2RkU4V3/EyzMR+WI5Y/2wPH/HYlnhnaA/229IdrSCmw5k44n1h7HiGV78d+z6ea9Um53o4BzVKwa56gQEVleQlYRXtx0BmfTtABMe4n8v75BeGlMZ7vYpv3z/dfw1i+XMKijN775az+pywFgmkdUWmFAabkBybnF+PlcBv57Nh25xabt8b3dHLD4wa54IDrA/JwMbSkGLN0FuUzA+cWj4eJgO4Mkjfn+Zo8KERHV0NHXDZufHYgvZvTByChfiCLwn2OpGL5sD9bsu4aScuu6enBjiKKIrWfTAQDDO/tKXM2f5DIBbo4K+Kgc0SfUE4sf7Iq9Lw/D3OEd4atyRE5ROZ779jRmfnkMP59LR0l5Jc6kFAAAOrVT2VRIaSz2qBAR0V0dS8rDop8umHdrDfZ0wXsPRWNABy+JK2u8FzedxQ9Vy5L3LBiKUG9XiSuqX4XBiBU7r+CTvddgMJq+sp2VcvNqrcf6BeOdSd2lLLHR2KNCREQWExvmiZ//NgjvPdQdARonpOSVYOqaI3ho9SH8eCoNZVVfmNbu6LVcc0h5eWykTYQUAFDKZXhpTGf89sK9eGZoBwR5OptDCgD0DvaQsLqWxx4VIiJqsMKyCizddhmbjqeisupf9xpnJWKC3BHm5YIQL1f0CHZv9v4gllZhMOLRTw/jVEoBpvULxts21gNxK1EUcTWrCGdSCpBTrMfsweF3XRlkjWzyWj9NwaBCRCSNLF0ZNp1IxX+OpeJGQWmtx0O9XDCxZ3s81i8Yvqo/V6SIoojsIj2+PZqCrw8nQyEXMKarH0ZGtYOjQoZATxcEaJwsFnKyCsuwYudVfHs0BQDgpJRh70vD7Ho5ry1gUCEiolZhMIo4nZKPxOwiJOWUIDG7CAcTclBSbhqacFDIMKKzL/KKy9FO7YTk3GLzaqI70Tgr0dHXDf3DPTEiqh1iAt0btfnc+TQtTqfmY/PpGzhdNeG02t+Gd8SLoyMb/TnJshhUiIhIMsX6SvwWl4mvDifXCgrVPFyUeHVcZ/iqnPDdyVScTimAo0KGtPxS85DSrcJ9XNEjyB19QjzRP9wTfhon80qX6gmm3x5LweZTaTh123t28Vfj1XGd4eHigK4B6jZ5AUZrw6BCRESSE0URx5LycCI5H4IA3NSWwUEhw9TYYIR6udYZGPSVBiRmFSMuQ4fd8VnYF5+NQn3t5dAywbQsVymX4UK6Frd/k/UIcodMABaN74oeQe4t9AmpqRhUiIjILlQajMgpKsex63lIzCrCvqvZuJShQ1lF7Z1alXIB93f3x6N9g21y6XRbwqBCRER2LUtXhnNpWhSXV6Jbew1E0bR7q7uL7e+c2xbYzNWTiYiImsJX7YSRXbhypy2wrYXXRERE1KYwqBAREZHVYlAhIiIiq8WgQkRERFaLQYWIiIisFoMKERERWS0GFSIiIrJaDCpERERktRhUiIiIyGoxqBAREZHVYlAhIiIiq8WgQkRERFaLQYWIiIislk1fPVkURQCmy0UTERGRbaj+3q7+Hr8bmw4qhYWFAICgoCCJKyEiIqLGKiwshEajues5gtiQOGOljEYj0tPToVKpEBsbi+PHj9d4vG/fvjWOVd/X6XQICgpCamoq1Gp1i9R2+3tb8jl3O+9Oj9V1vCHH2Gb1H7/b/ZZuN2trszs9xja7++P22GYNfR7brPHPs4c2E0URhYWFCAgIgEx291koNt2jIpPJEBgYCACQy+W1Gu72Y7ffV6vVLfalW1c9lnrO3c6702MNaZ+6jrHN6j9e332g5drN2trsTo+xze7+uD22WUOfxzZr/PPspc3q60mpZjeTaefMmVPvsbrOaSlNea+GPudu593psYa0T13H2Gb1H2eb1f8Y2+zuj9tjmzX0eWyzxj/PXtvsTmx66KepdDodNBoNtFpti/UO2Bu2WdOw3RqPbdZ4bLPGY5s1nlRtZjc9Ko3h6OiIN954A46OjlKXYjPYZk3Ddms8tlnjsc0aj23WeFK1WZvsUSEiIiLb0CZ7VIiIiMg2MKgQERGR1WJQISIiIqvFoEJERERWi0GFiIiIrBaDSj3i4+PRo0cP883Z2RlbtmyRuiyrl5SUhGHDhqFLly7o3r07iouLpS7J6oWGhiI6Oho9evTAsGHDpC7HZpSUlCAkJAQLFiyQuhSrV1BQgD59+qBHjx7o1q0b1qxZI3VJVi81NRVDhw5Fly5dEB0dje+++07qkmzCpEmT4OHhgYcffrjZr8XlyY1QVFSE0NBQJCcnw9XVVepyrNqQIUPw1ltvYfDgwcjLy4NarYZCYdNXbGhxoaGhuHDhAtzc3KQuxaYsXLgQCQkJCAoKwocffih1OVbNYDBAr9fDxcUFxcXF6NatG06cOAEvLy+pS7NaGRkZuHnzJnr06IHMzEz07t0bV65c4XdAPfbs2YPCwkKsW7cO33//fbNeiz0qjbB161aMGDGCv6D1uHjxIpRKJQYPHgwA8PT0ZEihFnH16lVcvnwZ48aNk7oUmyCXy+Hi4gIA0Ov1EEUR/Lfq3fn7+6NHjx4AAD8/P3h7eyMvL0/aomzA0KFDoVKpLPJaNh9U9u3bh/HjxyMgIACCINQ5LLNq1SqEhobCyckJ/fr1w7Fjx5r0Xps2bcKjjz7azIql19JtdvXqVbi5uWH8+PHo1asX3nnnHQtWL43W+D0TBAFDhgxB3759sX79egtVLp3WaLMFCxZg6dKlFqpYeq3RZgUFBYiJiUFgYCBeeukleHt7W6h6abTmd8DJkydhMBgQFBTUzKql1ZptZgk2H1SKi4sRExODVatW1fn4xo0bMX/+fLzxxhs4deoUYmJiMGbMGGRlZZnPqR6vvf2Wnp5uPken0+HQoUO47777WvwztbSWbrPKykrs378f//rXv3D48GH8/vvv+P3331vr47WI1vg9O3DgAE6ePImtW7finXfewblz51rls7WUlm6zn376CZ06dUKnTp1a6yO1uNb4PXN3d8fZs2eRlJSEb7/9Fjdv3myVz9ZSWus7IC8vD9OnT8dnn33W4p+ppbVWm1mMaEcAiJs3b65xLDY2VpwzZ475vsFgEAMCAsSlS5c26rW/+uorcdq0aZYo06q0RJsdOnRIHD16tPn++++/L77//vsWqdcatOTvWbUFCxaIX375ZTOqtC4t0WavvvqqGBgYKIaEhIheXl6iWq0WlyxZYsmyJdUav2fPPPOM+N133zWnTKvSUm1WVlYmDh48WPzqq68sVarVaMnfs927d4sPPfRQs2u0+R6VuykvL8fJkycxcuRI8zGZTIaRI0fi8OHDjXotexn2qY8l2qxv377IyspCfn4+jEYj9u3bh6ioqJYqWXKWaLPi4mIUFhYCME3a3rVrF7p27doi9VoDS7TZ0qVLkZqaiuvXr+PDDz/E7NmzsWjRopYqWXKWaLObN2+af8+0Wi327duHyMjIFqnXGliizURRxMyZMzF8+HA8/vjjLVWq1bDk96al2HVQycnJgcFgQLt27Wocb9euHTIzMxv8OlqtFseOHcOYMWMsXaLVsUSbKRQKvPPOO7j33nsRHR2NiIgIPPDAAy1RrlWwRJvdvHkTgwYNQkxMDPr374/p06ejb9++LVGuVbDU/5ttiSXaLDk5GYMHD0ZMTAwGDx6Mv/3tb+jevXtLlGsVLNFmBw8exMaNG7FlyxbzNhXnz59viXKtgqX+3xw5ciQeeeQR/PrrrwgMDGxWyOFSjAbQaDQ2P47b2saNG8eVGI0QHh6Os2fPSl2GzZo5c6bUJdiE2NhYnDlzRuoybMqgQYNgNBqlLsPm7Ny502KvZdc9Kt7e3pDL5bVCxs2bN+Hn5ydRVdaNbdZ4bLPGY5s1Htus8dhmjWeNbWbXQcXBwQG9e/fGH3/8YT5mNBrxxx9/YMCAARJWZr3YZo3HNms8tlnjsc0aj23WeNbYZjY/9FNUVISEhATz/aSkJJw5cwaenp4IDg7G/PnzMWPGDPTp0wexsbFYsWIFiouL8cQTT0hYtbTYZo3HNms8tlnjsc0aj23WeDbXZs1eNySx3bt3iwBq3WbMmGE+5+OPPxaDg4NFBwcHMTY2Vjxy5Ih0BVsBtlnjsc0aj23WeGyzxmObNZ6ttRmv9UNERERWy67nqBAREZFtY1AhIiIiq8WgQkRERFaLQYWIiIisFoMKERERWS0GFSIiIrJaDCpERERktRhUiIiIyGoxqBCR5EJDQ7FixQqpyyAiK8SdaYnaiJkzZ6KgoABbtmyRupRasrOz4erqChcXF6lLqZM1tx2RvWOPChG1mIqKigad5+PjI0lIaWh9RCQdBhUiAgBcuHAB48aNg5ubG9q1a4fHH38cOTk55se3b9+OQYMGwd3dHV5eXnjggQeQmJhofvz69esQBAEbN27EkCFD4OTkhPXr12PmzJmYOHEiPvzwQ/j7+8PLywtz5sypERJuH/oRBAGff/45Jk2aBBcXF0RERGDr1q016t26dSsiIiLg5OSEYcOGYd26dRAEAQUFBXf8jIIgYPXq1XjwwQfh6uqKt99+GwaDAbNmzUJYWBicnZ0RGRmJf/zjH+bnLF68GOvWrcNPP/0EQRAgCAL27NkDAEhNTcWUKVPg7u4OT09PTJgwAdevX2/afwAiqhODChGhoKAAw4cPR8+ePXHixAls374dN2/exJQpU8znFBcXY/78+Thx4gT++OMPyGQyTJo0CUajscZrvfrqq3j++edx6dIljBkzBgCwe/duJCYmYvfu3Vi3bh3Wrl2LtWvX3rWmJUuWYMqUKTh37hzuu+8+TJs2DXl5eQBMl6V/+OGHMXHiRJw9exZPPfUUFi5c2KDPunjxYkyaNAnnz5/Hk08+CaPRiMDAQHz33XeIi4vDokWL8L//+7/YtGkTAGDBggWYMmUKxo4di4yMDGRkZOCee+5BRUUFxowZA5VKhf379+PgwYNwc3PD2LFjUV5e3tCmJ6L6SHbdZiJqVTNmzBAnTJhQ52N///vfxdGjR9c4lpqaKgIQ4+Pj63xOdna2CEA8f/68KIqimJSUJAIQV6xYUet9Q0JCxMrKSvOxRx55RHz00UfN90NCQsTly5eb7wMQX3/9dfP9oqIiEYC4bds2URRF8ZVXXhG7detW430WLlwoAhDz8/PrboCq1503b94dH682Z84c8aGHHqrxGW5vu6+//lqMjIwUjUaj+ZherxednZ3FHTt21PseRNQw7FEhIpw9exa7d++Gm5ub+da5c2cAMA/vXL16FVOnTkV4eDjUajVCQ0MBACkpKTVeq0+fPrVev2vXrpDL5eb7/v7+yMrKumtN0dHR5p9dXV2hVqvNz4mPj0ffvn1rnB8bG9ugz1pXfatWrULv3r3h4+MDNzc3fPbZZ7U+1+3Onj2LhIQEqFQqc5t5enqirKysxpAYETWPQuoCiEh6RUVFGD9+PN57771aj/n7+wMAxo8fj5CQEKxZswYBAQEwGo3o1q1brWEOV1fXWq+hVCpr3BcEodaQkSWe0xC317dhwwYsWLAAy5Ytw4ABA6BSqfDBBx/g6NGjd32doqIi9O7dG+vXr6/1mI+PT7PrJCITBhUiQq9evfDDDz8gNDQUCkXtvxZyc3MRHx+PNWvWYPDgwQCAAwcOtHaZZpGRkfj1119rHDt+/HiTXuvgwYO455578Oyzz5qP3d4j4uDgAIPBUONYr169sHHjRvj6+kKtVjfpvYmofhz6IWpDtFotzpw5U+OWmpqKOXPmIC8vD1OnTsXx48eRmJiIHTt24IknnoDBYICHhwe8vLzw2WefISEhAbt27cL8+fMl+xxPPfUULl++jFdeeQVXrlzBpk2bzJNzBUFo1GtFRETgxIkT2LFjB65cuYL/+7//qxV6QkNDce7cOcTHxyMnJwcVFRWYNm0avL29MWHCBOzfvx9JSUnYs2cP5s6di7S0NEt9VKI2j0GFqA3Zs2cPevbsWeO2ZMkSBAQE4ODBgzAYDBg9ejS6d++OefPmwd3dHTKZDDKZDBs2bMDJkyfRrVs3vPDCC/jggw8k+xxhYWH4/vvv8eOPPyI6OhqrV682r/pxdHRs1Gs99dRTmDx5Mh599FH069cPubm5NXpXAGD27NmIjIxEnz594OPjg4MHD8LFxQX79u1DcHAwJk+ejKioKMyaNQtlZWXsYSGyIO5MS0R24e2338Ynn3yC1NRUqUshIgviHBUiskn/+te/0LdvX3h5eeHgwYP44IMP8Nxzz0ldFhFZGIMKEdmkq1ev4q233kJeXh6Cg4Px4osv4rXXXpO6LCKyMA79EBERkdXiZFoiIiKyWgwqREREZLUYVIiIiMhqMagQERGR1WJQISIiIqvFoEJERERWi0GFiIiIrBaDChEREVktBhUiIiKyWv8fxvuNHX2MSl8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to: logs/Regression/california_housing/ViT/IGTD_3x3_fEuclidean_iEuclidean_abs_Model2/lr_finder_plot.png\n",
      "Suggested learning rate: 0.0002283997647078464\n"
     ]
    }
   ],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created and tested Model2\n",
      "\n",
      "Training completed in 446.10 seconds\n",
      "Best model found at epoch 95/100\n",
      "Best Train Loss: 0.3495, Best Val Loss: 0.3651\n",
      "Best Train MSE: 0.3495, Best Val MSE: 0.3664\n",
      "Best Train RMSE: 0.5912, Best Val RMSE: 0.6053\n",
      "Best model saved to models/Regression/california_housing/ViT/IGTD_3x3_fEuclidean_iEuclidean_abs_Model2/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=5e-6, max_lr=3e-3)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Metrics: {'train_loss': 0.3347183215872262, 'train_mse': 0.33471834659576416, 'train_mae': 0.40622246265411377, 'train_rmse': 0.5785484824937009, 'train_r2': 0.7476895451545715, 'val_loss': 0.3663120143688642, 'val_mse': 0.3669319748878479, 'val_mae': 0.42821022868156433, 'val_rmse': 0.6057491022592175, 'val_r2': 0.7178716659545898, 'test_loss': 0.3658551117548576, 'test_mse': 0.36362266540527344, 'test_mae': 0.4253979027271271, 'test_rmse': 0.6030113310753566, 'test_r2': 0.7404434680938721, 'min_lr': 1e-05, 'max_lr': 0.004, 'total_time': 276.4513289928436, 'average_epoch_time': 2.7645096468925474}\n",
      "Model 2 Metrics: {'train_loss': 0.3468046650406002, 'train_mse': 0.3468046486377716, 'train_mae': 0.41022396087646484, 'train_rmse': 0.5889012214605872, 'train_r2': 0.7385789155960083, 'val_loss': 0.3651486740662501, 'val_mse': 0.3663583993911743, 'val_mae': 0.4250083565711975, 'val_rmse': 0.6052754739712938, 'val_r2': 0.718312680721283, 'test_loss': 0.36380844895656295, 'test_mse': 0.36234062910079956, 'test_mae': 0.4244697093963623, 'test_rmse': 0.6019473640616757, 'test_r2': 0.7413586378097534, 'min_lr': 5e-06, 'max_lr': 0.003, 'total_time': 446.097216129303, 'average_epoch_time': 4.460967924594879}\n"
     ]
    }
   ],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the dataframe\n",
    "num_columns = df.shape[1]\n",
    "\n",
    "# Calculate number of columns - 1\n",
    "columns_minus_one = num_columns - 1\n",
    "\n",
    "# Calculate the square root for image size\n",
    "import math\n",
    "image_size = math.ceil(math.sqrt(columns_minus_one))\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], fea_dist_method='Euclidean', image_dist_method='Euclidean', error='abs', max_step=30000, val_step=300, random_seed=SEED)\n",
    "name = f\"IGTD_{image_size}x{image_size}_fEuclidean_iEuclidean_abs\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The images are already generated\n",
      "HyNNImages/Regression/california_housing/images_california_housing_IGTD_3x3_fEuclidean_iEuclidean_abs/regression.csv\n",
      "Images shape:  (3, 3, 3)\n",
      "Attributes:  8\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created and tested Model1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca5347c93e443198dda71bf2b51157c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 1.78E-01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to: logs/Regression/california_housing/ViT/IGTD_3x3_fEuclidean_iEuclidean_abs_Model1_patch_s1/lr_finder_plot.png\n",
      "Suggested learning rate: 0.1778279410038924\n"
     ]
    }
   ],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1_patch_s1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created and tested Model1\n",
      "\n",
      "Training completed in 283.70 seconds\n",
      "Best model found at epoch 52/100\n",
      "Best Train Loss: 1.3318, Best Val Loss: 1.2966\n",
      "Best Train MSE: 1.3318, Best Val MSE: 1.3006\n",
      "Best Train RMSE: 1.1540, Best Val RMSE: 1.1405\n",
      "Best model saved to models/Regression/california_housing/ViT/IGTD_3x3_fEuclidean_iEuclidean_abs_Model1_patch_s1/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1_patch_s1\", min_lr=1e-5, max_lr=4e-3)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created and tested Model2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4644de8c59f247279aa10846761753d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/645 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 1.35E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to: logs/Regression/california_housing/ViT/IGTD_3x3_fEuclidean_iEuclidean_abs_Model2_patch_s1/lr_finder_plot.png\n",
      "Suggested learning rate: 0.00013503140378698733\n"
     ]
    }
   ],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2_patch_s1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created and tested Model2\n",
      "\n",
      "Training completed in 434.00 seconds\n",
      "Best model found at epoch 41/100\n",
      "Best Train Loss: 1.3355, Best Val Loss: 1.2966\n",
      "Best Train MSE: 1.3355, Best Val MSE: 1.3006\n",
      "Best Train RMSE: 1.1556, Best Val RMSE: 1.1404\n",
      "Best model saved to models/Regression/california_housing/ViT/IGTD_3x3_fEuclidean_iEuclidean_abs_Model2_patch_s1/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2_patch_s1\", min_lr=5e-6, max_lr=2e-3)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Metrics: {'train_loss': 1.328244388218998, 'train_mse': 1.3282444477081299, 'train_mae': 0.9036785960197449, 'train_rmse': 1.1524948796884653, 'train_r2': -0.0012298822402954102, 'val_loss': 1.2965735481335567, 'val_mse': 1.3006327152252197, 'val_mae': 0.8874601125717163, 'val_rmse': 1.1404528553277509, 'val_r2': -3.635883331298828e-05, 'test_loss': 1.4067012612636274, 'test_mse': 1.403048038482666, 'test_mae': 0.9331672191619873, 'test_rmse': 1.1845032876622446, 'test_r2': -0.0015058517456054688, 'min_lr': 1e-05, 'max_lr': 0.004, 'total_time': 283.69513154029846, 'average_epoch_time': 2.8369472932815554}\n",
      "Model 2 Metrics: {'train_loss': 1.3279084713422051, 'train_mse': 1.3279083967208862, 'train_mae': 0.9044119119644165, 'train_rmse': 1.152349077632679, 'train_r2': -0.0009765625, 'val_loss': 1.2965682442371662, 'val_mse': 1.3005914688110352, 'val_mae': 0.8883318305015564, 'val_rmse': 1.140434771835301, 'val_r2': -4.76837158203125e-06, 'test_loss': 1.406289882843311, 'test_mse': 1.4026633501052856, 'test_mae': 0.933894693851471, 'test_rmse': 1.184340892693183, 'test_r2': -0.0012313127517700195, 'min_lr': 5e-06, 'max_lr': 0.002, 'total_time': 434.0021102428436, 'average_epoch_time': 4.340017268657684}\n"
     ]
    }
   ],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], fea_dist_method='Euclidean', image_dist_method='Euclidean', error='abs', max_step=30000, val_step=300, random_seed=SEED)\n",
    "name = f\"IGTD_{image_size*2}x{image_size*2}_fEuclidean_iEuclidean_abs\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=5e-3, max_lr=6e-2)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=1e-3, max_lr=8e-2)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], fea_dist_method='Euclidean', image_dist_method='Euclidean', error='abs', max_step=30000, val_step=300, random_seed=SEED)\n",
    "name = f\"IGTD_{image_size*4}x{image_size*4}_fEuclidean_iEuclidean_abs\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=5e-3, max_lr=2e-1)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=5e-3, max_lr=2e-1)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], random_seed=SEED)\n",
    "name = f\"IGTD_{image_size}x{image_size}\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=1e-5, max_lr=4e-3)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=5e-6, max_lr=4e-3)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], zoom=2, random_seed=SEED)\n",
    "name = f\"IGTD_{image_size*2}x{image_size*2}\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=2e-5, max_lr=1e-2)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=7e-6, max_lr=3e-3)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = IGTD(problem= problem_type, scale=[image_size,image_size], zoom=4, random_seed=SEED)\n",
    "name = f\"IGTD_{image_size*4}x{image_size*4}\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=1e-5, max_lr=1e-2)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=2e-6, max_lr=5e-3)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EXPERIMENT 3: REFINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = REFINED(problem= problem_type, random_seed=SEED)\n",
    "name = f\"REFINED\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=3e-4, max_lr=1e-2)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=8e-5, max_lr=1e-3)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = REFINED(problem= problem_type, zoom=2, random_seed=SEED)\n",
    "name = f\"REFINED_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=5e-3, max_lr=2e-1)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=8e-3, max_lr=3e-2)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = REFINED(problem= problem_type, zoom=4, random_seed=SEED)\n",
    "name = f\"REFINED_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=5e-3, max_lr=9e-2)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=2e-3, max_lr=1e-1)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EXPERIMENT 4: BAR GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = BarGraph(problem= problem_type)\n",
    "name = f\"BarGraph\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=2e-3, max_lr=2e-1)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=1e-4, max_lr=1e-1)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = BarGraph(problem= problem_type, zoom=2)\n",
    "name = f\"BarGraph_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=2e-3, max_lr=2e-1)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=5e-4, max_lr=1e-1)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = BarGraph(problem= problem_type, zoom=4)\n",
    "name = f\"BarGraph_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=5e-3, max_lr=2e-1)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=5e-4, max_lr=9e-2)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EXPERIMENT 5: DISTANCE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = DistanceMatrix(problem= problem_type)\n",
    "name = f\"DistanceMatrix\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=1e-2, max_lr=2e-1)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=1e-3, max_lr=6e-2)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = DistanceMatrix(problem= problem_type, zoom=2)\n",
    "name = f\"DistanceMatrix_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=1e-3, max_lr=6e-2)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=1e-3, max_lr=2e-1)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = DistanceMatrix(problem= problem_type, zoom=4)\n",
    "name = f\"DistanceMatrix_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=1e-3, max_lr=2e-1)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=1e-3, max_lr=5e-2)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EXPERIMENT 6: COMBINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = Combination(problem= problem_type)\n",
    "name = f\"Combination\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=1e-2, max_lr=5e-2)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=2e-3, max_lr=1e-1)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = Combination(problem= problem_type, zoom=2)\n",
    "name = f\"Combination_zoom2\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=1e-3, max_lr=2e-1)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=5e-4, max_lr=1.5e-2)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = Combination(problem= problem_type, zoom=4)\n",
    "name = f\"Combination_zoom4\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=5e-3, max_lr=2e-1)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=1e-3, max_lr=6e-2)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EXPERIMENT 7: SUPERTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = SuperTML(problem= problem_type, random_seed=SEED)\n",
    "name = f\"SuperTML-EF\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=2e-3, max_lr=2e-1)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=1e-2, max_lr=3e-2)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = SuperTML(problem= problem_type, feature_importance=True, font_size=30, random_seed=SEED)\n",
    "name = f\"SuperTML-VF_FS30\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=1e-3, max_lr=2e-1)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=1e-3, max_lr=1e-1)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### EXPERIMENT 8: FEATURE WRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "problem_type = \"regression\"\n",
    "image_model = FeatureWrap(problem = problem_type)\n",
    "name = f\"FeatureWrap\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "images_folder = f\"../HyNNImages/Regression/{dataset_name}/images_{dataset_name}_{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader, attributes, imgs_shape  = load_and_preprocess_data(images_folder, image_model, problem_type, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine possible patch sizes for the Vision Transformer by finding divisors of the image width\n",
    "find_divisors(imgs_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model1, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model1\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model1\n",
    "model1 = try_create_model(Model1, patch_size, imgs_shape)  # Attempt to create Model1\n",
    "model1_metrics = safe_compile_and_fit(model1, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model1\", min_lr=2e-5, max_lr=2e-2)  # Train and evaluate Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = run_lr_finder(Model2, patch_size, attributes, imgs_shape, dataset_name, f\"{name}_Model2\", train_loader, val_loader, num_iter=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Model2\n",
    "model2 = try_create_model(Model2, patch_size, imgs_shape)  # Attempt to create Model2\n",
    "model2_metrics = safe_compile_and_fit(model2, train_loader, val_loader, test_loader, dataset_name, f\"{name}_Model2\", min_lr=5e-6, max_lr=3e-3)  # Train and evaluate Model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comparison of metrics only for models that ran successfully\n",
    "if model1_metrics:\n",
    "    print(\"Model 1 Metrics:\", model1_metrics)  # Print metrics for Model1 if available\n",
    "if model2_metrics:\n",
    "    print(\"Model 2 Metrics:\", model2_metrics)  # Print metrics for Model2 if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## FINAL METRICS AND BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(base_path):\n",
    "    best_rmse = float('inf')\n",
    "    best_folder = None\n",
    "\n",
    "    # Walk through all directories and files in the base path\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file == f'metrics.txt':\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Read metrics from the file\n",
    "                with open(file_path, 'r') as f:\n",
    "                    metrics = f.read()\n",
    "                \n",
    "                # Parse the metrics into a dictionary\n",
    "                metrics_dict = {}\n",
    "                for line in metrics.splitlines():\n",
    "                    key, value = line.split(': ')\n",
    "                    metrics_dict[key.strip()] = float(value.strip())\n",
    "                \n",
    "                # Check if the current folder has a better validation loss\n",
    "                if metrics_dict['test_rmse'] < best_rmse:\n",
    "                    best_rmse = metrics_dict['test_rmse']\n",
    "                    best_folder = root\n",
    "    \n",
    "    return best_folder, best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_metrics(file_path):\n",
    "    metrics = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            key, value = line.split(': ')\n",
    "            metrics[key.strip()] = float(value.strip())\n",
    "    return metrics\n",
    "\n",
    "def rename_folder(old_folder_path, prefix):\n",
    "    folder_name = os.path.basename(old_folder_path)\n",
    "    new_folder_name = f\"{prefix}_{folder_name}\"\n",
    "    parent_dir = os.path.dirname(old_folder_path)\n",
    "    new_folder_path = os.path.join(parent_dir, new_folder_name)\n",
    "    os.rename(old_folder_path, new_folder_path)\n",
    "    return new_folder_path\n",
    "\n",
    "def process_folders(root_dir):\n",
    "    prefixes = [\"TINTO\", \"BarGraph\", \"Combination\", \"DistanceMatrix\", \"IGTD\", \"REFINED\", \"SuperTML\", \"FeatureWrap\"]\n",
    "    best_folders = []\n",
    "\n",
    "    for prefix in prefixes:\n",
    "        matching_folders = [f for f in os.listdir(root_dir) if f.startswith(prefix) and os.path.isdir(os.path.join(root_dir, f))]\n",
    "        if matching_folders:\n",
    "            best_folder = None\n",
    "            best_test_rmse = float('inf')\n",
    "            for folder in matching_folders:\n",
    "                metrics_file = os.path.join(root_dir, folder, 'metrics.txt')\n",
    "                if os.path.exists(metrics_file):\n",
    "                    metrics = read_metrics(metrics_file)\n",
    "                    if metrics['test_rmse'] < best_test_rmse:\n",
    "                        best_test_rmse = metrics['test_rmse']\n",
    "                        best_folder = folder\n",
    "            if best_folder:\n",
    "                new_path = rename_folder(os.path.join(root_dir, best_folder), \"TOP\")\n",
    "                best_folders.append(new_path)\n",
    "    \n",
    "    if best_folders:\n",
    "        overall_best_folder = None\n",
    "        overall_best_test_rmse = float('inf')\n",
    "        for folder in best_folders:\n",
    "            metrics_file = os.path.join(folder, 'metrics.txt')\n",
    "            if os.path.exists(metrics_file):\n",
    "                metrics = read_metrics(metrics_file)\n",
    "                if metrics['test_rmse'] < overall_best_test_rmse:\n",
    "                    overall_best_test_rmse = metrics['test_rmse']\n",
    "                    overall_best_folder = folder\n",
    "        if overall_best_folder:\n",
    "            rename_folder(overall_best_folder, \"BEST\")\n",
    "        \n",
    "    return best_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "base_path = f\"logs/Regression/{dataset_name}/ViT/\"\n",
    "best_folders = process_folders(base_path)\n",
    "print(f\"Best model folder: {best_folders}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
